### CNN은 이미지의 어느 위치를 보는가?

완전 연결층을 거치면 Flatten을 거치기에 설명이 부족해짐

cam을 사용하게 되면서 완전연결층 대신 GAP를 사용해 어느 곳을 보고 판단하는지 확인이 가능

잘못된 곳을 보고 판단하는게 확인되면 역전파 과정을 거쳐 다시 학습을 시켜야함

### CAM과 Grad-CAM의 차이점

| 구분 | CAM (Class Activation Mapping) | Grad-CAM (Gradient-weighted Class Activation Map) |
| --- | --- | --- |
| **작동 방식** | GAP(Global Average Pooling)를 사용해 특징 맵을 결합 | Gradient(경사) 정보를 이용해 특징 맵을 결합 |
| **모델 구조 변경** | 모델의 마지막 레이어를 **GAP**로 바꿔야 함. | 모델 구조를 **그대로** 사용할 수 있음. |
| **범용성** | 모델의 구조를 바꿔야 하므로 범용성이 떨어짐. | 모델 구조 변경 없이 다양한 CNN 모델에 적용 가능. |

---

### 이미지 클래스피케이션(Image Classification)

컴퓨터가 주어진 이미지를 보고, 그 이미지가 어떤 범주(클래스)에 속하는지 예측하는 작업

쉽게 말해, 사진을 보고 그 안에 있는 사물이 무엇인지 맞추는 거

### 이미지 클래스피케이션의 과정

1. **입력**: 컴퓨터에게 강아지, 고양이, 새 등 여러 종류의 사진을 보여줘.
2. **학습**: 컴퓨터는 이 사진들을 보면서 각 동물의 특징을 배워. 예를 들어, 뾰족한 귀는 고양이일 확률이 높고, 짖는 소리를 낸다면 강아지일 확률이 높다는 식으로 말이야. 이 과정에서 CNN 같은 딥러닝 모델이 사용돼.
3. **예측**: 학습을 마친 컴퓨터에게 새로운 사진을 보여주면, 컴퓨터는 스스로 학습한 내용을 바탕으로 사진 속 동물이 **강아지인지, 고양이인지, 아니면 다른 동물인지** 예측하고, 그에 대한 확률 값을 알려줘.

### Logits & Softmax의 역할

**Logits**는 모델이 각 클래스에 대해 예측한 실제 수치(점수). 

이 값들은 양수나 음수가 될 수 있고, 그 범위는 정해져 있지 않음. 

쉽게 말해, 모델이 생각하는 각 클래스의 확신 점수다.

**Softmax 함수**는 이 '확신 점수'들을 **확률 값**으로 바꿔주는 역할

- **지수 함수**를 사용해서 모든 logit 값을 양수로 만들고,
- 그 값들을 모두 더한 값으로 나누어 **0에서 1 사이의 값**으로 바꿈
- 이렇게 변환된 값들은 모두 더하면 **1**이 된다.

이 과정을 거치면, 모델이 "이 이미지는 강아지일 확률이 80%, 고양이일 확률이 5%, 호랑이일 확률이 0%, 사자일 확률이 15%"라고 말하는 것처럼, **각 클래스에 대한 상대적인 확률**을 얻게 됨

**결론**

**Logits는 모델의 원시 점수**

**Softmax는 그 점수들을 사람들이 이해하기 쉬운 확률로 변환해주는 역할**

규칙기반: 예전에 사용하던 방식. 사람이 직접 컴퓨터에게 규칙을 알려

데이터기반: 이방식으로 큰 성공을 거둔 컴퓨터 비전 태스크. 컴퓨터가 스스로 배움

### 세 가지 이미지 분 데이터셋 비교

| 특징 | **MNIST** | **CIFAR-10** | **ImageNet** |
| --- | --- | --- | --- |
| **이미지 종류** | 손글씨 숫자 (0-9) | 10가지 사물 및 동물 | 1,000가지 사물 및 동물 |
| **이미지 크기** | 28x28 픽셀 | 32x32 픽셀 | 평균 469x387 픽셀 <br> (학습 시 256x256으로 통일) |
| **데이터 수** | 7만 개 | 6만 개 | 120만 개 이상 |
| **학습 난이도** | 쉬움 | 보통 | 매우 어려움 |
| **장점** | 딥러닝 입문용으로 좋고, 연산량이 적어 학습이 빨라. | 현실 이미지를 다루는 모델에 적합하고, MNIST보다 복잡한 문제를 다룰 수 있어. | 압도적으로 많은 데이터로 훨씬 더 정교하고 강력한 모델을 만들 수 있어. |
| **단점** | 현실 문제에 적용하기 어려워. | ImageNet에 비해 데이터 양이 적어 더 복잡한 모델에는 한계가 있어. | 데이터 양이 너무 많아서 학습 시간이 매우 오래 걸리고, 고성능 컴퓨터가 필요해. |
| **주요 사용처** | 딥러닝 모델의 기본 성능 테스트나 초보자 학습용 | 이미지 분류 모델의 성능 평가나 연구용 | 대규모 이미지 인식 모델 개발이나 연구용 |

## 딥러닝 이미지 분류 프로세스 총정리

| 단계 | 과정 | 설명 |
| --- | --- | --- |
| **학습 (Training)** | **1. 데이터셋 준비**(MNIST, CIFAR-10, ImageNet 등) | 컴퓨터가 이미지 특징을 스스로 배우도록 **레이블이 달린** 방대한 양의 사진 데이터를 준비 |
|  | **2. 전처리**(Preprocessing) | 모델이 데이터를 더 잘 이해하도록 이미지의 크기를 통일하거나, 회전시키거나, 색상을 바꾸는 등 데이터를 다듬기 |
|  | **3. 모델 학습**(Model) | 전처리된 데이터를 신경망 모델에 넣어서 모델이 이미지의 특징을 스스로 학습하도록 훈련. 이 과정에서 **Batch Normalization**이나 **Dropout** 같은 기술을 사용해서 학습 성능을 높임 |
|  | **4. 손실 계산**(Loss) | 모델이 예측한 결과와 실제 정답 사이의 차이(오차)를 계산하고, 이 오차를 줄이는 방향으로 모델을 계속 수정 |
| --- | --- | --- |
| **테스트 (Testing)** | **1. 테스트 데이터 입력**(Test Data) | 학습이 완료된 모델에 **새로운 이미지**를 입력해서 모델이 얼마나 잘 예측하는지 성능을 평가 |
|  | **2. 전처리**(Preprocessing) | 학습 때와 **동일한 방법**으로 테스트 이미지를 전처리 |
|  | **3. 모델 예측**(Prediction) | 모델이 입력된 이미지를 분석해서 어떤 클래스에 속하는지 **예측** |
|  | **4. 최종 결과 출력**(Softmax Classifier) | 예측 결과로 각 클래스에 대한 **확률**을 계산하고, 가장 높은 확률을 가진 클래스를 **최종 정답**으로 결정 |

### 딥러닝 모델 평가 지표 총정리

| 지표 | 수식 | 설명 | 주요 사용 사례 |
| --- | --- | --- | --- |
| **정확도**(Accuracy) | TP+TN+FP+FNTP+TN | 전체 예측 중에서 **올바르게 맞힌 예측의 비율**. 가장 직관적이고 보편적인 지표임. | 데이터가 고르게 분포되어 있을 때 (정답과 오답의 비율이 비슷할 때) |
| **정밀도**(Precision) | TP+FPTP | 모델이 **'정답'이라고 예측한 것들 중**에서 **실제로 정답인 비율**. 잘못된 긍정 예측(FP)이 중요한 경우에 사용됨. | 스팸 메일 분류 (중요한 메일이 스팸으로 오분류되는 경우를 줄여야 할 때) |
| **재현율**(Recall) | TP+FNTP | **실제 정답 중에서** 모델이 **정답이라고 제대로 찾아낸 비율**. 놓치면 안 되는 정답(FN)이 중요한 경우에 사용됨. | 암 진단 (실제 암 환자를 놓치지 않고 찾아내는 것이 중요할 때) |
| **F1-점수**(F1-Score) | 2×Precision+RecallPrecision×Recall | 정밀도와 재현율의 **조화 평균**. 두 지표의 균형을 모두 고려해야 할 때 사용됨. | 데이터가 불균형하거나, 정밀도와 재현율 모두 중요할 때 |

### 혼동 행렬 (Confusion Matrix) 용어 정리

위 지표들을 이해하려면 혼동 행렬의 네 가지 기본 용어를 알아야 한다.

- **TP (True Positive)**: 실제 정답을 **정답**이라고 예측. (맞게 예측)
- **TN (True Negative)**: 실제 오답을 **오답**이라고 예측. (맞게 예측)
- **FP (False Positive)**: 실제 오답을 **정답**이라고 **잘못** 예측. (오진, Type I Error)
- **FN (False Negative)**: 실제 정답을 **오답**이라고 **잘못** 예측. (놓침, Type II Error)

---

## 객체 탐지 (Object Detection)

사진이나 영상 속에서 **물체의 위치를 찾아내고, 그 물체가 무엇인지 분류하는 기술**

### 작동 방식

1. **위치 찾기**: 이미지 안의 여러 물체들을 하나씩 찾아낸다.
2. **분류**: 찾아낸 각 물체가 무엇인지 (예: 사람, 자동차, 자전거)를 분류한다.
3. **경계 상자**: 찾아낸 물체마다 그 위치에 맞춰 사각형 상자를 표시한다.

예를 들어, 객체 탐지 모델은 단순히 "이 사진은 도로 사진"이라고 말하는 대신, 

"이 사진에 사람 2명, 자동차 1대, 자전거 1대가 있고, 각각의 위치는 이렇다"고 알려준다.

| 단계 | 역할 | 세부 설명 |
| --- | --- | --- |
| **1. 입력** | **이미지 또는 영상** | 탐지하고자 하는 이미지나 영상을 모델에 입력 |
| **2. 특징 추출** | **Backbone (주로 CNN)** | 입력된 이미지에서 물체들을 구별할 수 있는 특징을 찾아냄 |
| **3. 위치 및 분류 예측** | **Decoder (Detection Head)** | 추출된 특징을 바탕으로 **위치**와 **종류**를 동시에 예측 |
| **4. 출력** | **경계 상자(Bounding Box) 및 라벨** | 최종적으로 물체의 위치를 사각형 상자로 표시, 그 물체의 종류를 보여준다. |

### 주요 활용 분야

- **자율 주행**: 도로 위의 차량, 사람, 신호등 등을 실시간으로 감지한다.
- **보안 감시**: CCTV 영상에서 수상한 물체나 사람의 움직임을 탐지한다.
- **의료 영상 분석**: X-ray나 MRI 사진에서 종양 같은 특정 객체를 찾아낸다.

### **1단계,2단계detector 차이 비교**

| 특징 | **1단계 탐지기 (YOLO, SSD)** | **2단계 탐지기 (R-CNN, Fast R-CNN)** |
| --- | --- | --- |
| **속도** | **빠름** | **느림** |
| **정확도** | 보통 | 높음 |
| **프로세스** | 1단계 (한 번에) | 2단계 (두 번에) |
| **주요 방식** | 입력 이미지를 한 번에 처리해서<br>위치와 분류를 동시에 예측함. | 1. 물체가 있을 만한 위치(Region Proposal)를 먼저 찾음.<br>2. 찾은 영역을 다시 분석해서 최종 위치와 분류를 예측함. |
| **장점** | 실시간 객체 탐지에 적합함. | 정확도가 매우 높아 정밀한 분석에 유리함. |
| **단점** | 정확도가 상대적으로 낮아 작은 물체 탐지에 취약함. | 연산량이 많아 속도가 느림. |

### **객체 탐지에 주로 사용되는 데이터셋 3가지(Pascal VOC, COCO, KITTI) 비교**

| 특징 | **Pascal VOC** | **COCO** | **KITTI** |
| --- | --- | --- | --- |
| **클래스 수** | 20개 | 91개 | 8개 |
| **데이터 양** | 1.1만 이미지 2.7만 어노테이션 | 33만 이미지 150만 어노테이션 | 1.5만 이미지 8만 어노테이션 |
| **이미지 크기** | 500x375 | 최대 640x480 | 1248x384 |
| **주요 특징** | - 비교적 적은 데이터와 클래스                                     - 객체 탐지 초기 연구에 많이 사용됨 | - **가장 크고 복잡한 데이터셋**<br>- 다양한 환경의 물체 포함<br>- 최신 모델 성능 평가의 표준 | - **자율주행에 특화**<br>- 도로 환경의 물체(차, 사람, 자전거 등)에 집중 |
| **장점** | - 데이터셋 크기가 작아 학습하기 용이함<br>- 초기 모델의 성능 검증에 적합함 | - 방대한 데이터로 높은 정확도의 모델을 만들 수 있음<br>- 현실의 복잡한 상황을 잘 반영함 | - 자율주행 관련 연구에 필수적임<br>- 도로 환경에 최적화된 모델을 만들 수 있음 |
| **단점** | - 데이터 양이 적어 복잡한 모델 학습에 한계가 있음 | - 학습 시간이 오래 걸리고 고성능 컴퓨팅 자원이 필요함 | - 특정 도메인(자율주행)에만 특화되어 범용성이 낮음 |

---

## 성능 평가 방법

객체 탐지 모델이 물체의 위치를 얼마나 정확하게 예측했는지 측정하는 방법

### 1. IoU (Intersection over Union)

모델이 예측한 경계 상자(Prediction)와 실제 정답 경계 상자(Ground Truth)가 겹치는 비율

![image.png](attachment:c6c7614a-b0bb-4572-a7cd-18339230b6c9:image.png)

- **Intersection (교집합)**: 파란색 예측 상자와 초록색 정답 상자가 겹치는 부분
- **Union (합집합)**: 두 상자를 합쳤을 때 전체 영역

IoU 값이 **1에 가까울수록** 모델이 물체의 위치를 아주 정확하게 예측했다는 뜻이고, 

**0에 가까울수록** 예측이 엉망이라는 뜻

### 2. 평균 정밀도(Average Precision, AP)

AP는 **객체 탐지** 모델의 성능을 평가하는 데 주로 사용되는 지표
객체 탐지 모델이 얼마나 정확하게 물체의 **위치와 종류**를 맞췄는지 평가하는 지표

### 정밀도와 재현율

- **정밀도(Precision)**: 모델이 **'정답'이라고 예측한 것들 중에서 실제로 정답인 비율**
    
    Precision=TP+FPTP
    
    - `TP`: 정답을 정답이라고 맞게 예측함 (True Positive)
    - `FP`: 오답을 정답이라고 잘못 예측함 (False Positive)
- **재현율(Recall)**: **실제 정답 중에서 모델이 정답이라고 제대로 찾아낸 비율**
    
    Recall=TP+FNTP
    
    - `FN`: 정답을 오답이라고 잘못 예측함 (False Negative)

객체 탐지에서는 IoU라는 기준을 사용해 예측이 얼마나 정확했는지 판단 

예) IoU가 0.5를 넘으면 이 예측은 성공이라고 판단함

AP는 이처럼 **다양한 IoU 임계점**에서 모델의 정밀도를 계산한 뒤,

그 값들의 **평균**을 내서 최종 점수를 산출

예) IoU 0.5에서의 AP는 **AP50**, IoU 0.75에서의 AP는 **AP75**라고 부름. 

최종적으로 **AP**는 이 여러 AP 값들의 평균을 내서 종합적인 성능을 평가. 

AP가 높을수록 물체의 위치와 종류를 정확하게 잘 찾아내는 모델이라는 뜻

결론, IoU는 모델이 물체 위치를 얼마나 잘 맞췄나? 를 보는 지표, 

AP는 모델이 물체 위치와 종류를 얼마나 정확하고 안정적으로 맞췄나?를 보는 종합 지표 

그래서 AP를 보는 게 훨씬 중요함

---

### 2단계 탐지기 (2-stage Detector)

**객체 탐지** 모델 중에서도 **정확도를 극대화**하기 위해 고안된 방식
물체를 탐지할 때 **영역 제안과 분류 및 위치 예측의 두 단계를 거치는 모델**을 말함 

정확도가 높지만 속도가 느림

1. **Region Proposals(리전 프로포절스) (영역 제안):** 모델이 이미지를 한 번 훑어보면서 **물체가 있을 만한 영역**을 대략적으로 여러 개 제안한다.
    - 이 과정 덕분에 모든 픽셀을 일일이 분석하지 않고 효율적으로 물체 후보를 찾아냄

1. **Classification & Regression: (클래시피케이션 앤 리그레션) 분류와 회귀**
    - 제안된 영역들(Warped Region)을 하나씩 가져와서 다시 분석
    - **Backbone**을 통해 더 정확한 특징을 추출
    - 추출된 특징을 바탕으로 SVM classifier(SVM 분류기)를 이용해 해당 영역이 어떤 물체인지(Category)를 최종적으로 분류
    - Bbox Regressor(경계 상자 회귀)를 사용해 경계 상자의 위치를 더 정교하게 수정

**2단계 탐지기의 가장 큰 특징은 이렇게 두 단계에 걸쳐 물체를 탐지한다는 점.** 

이 때문에 1단계 탐지기보다 **속도는 느리지만, 정확도는 훨씬 높다**. 

R-CNN 계열 모델(R-CNN, Fast R-CNN 등)이 바로 이 2단계 방식의 대표적인 예
