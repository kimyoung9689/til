# CNN(Convolutional Neural Network) 완전 정리

## 목차

1. [CNN 개요](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
2. [CNN의 기본 구조](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
3. [Convolution Layer 상세](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
4. [Activation Function](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
5. [Pooling Layer](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
6. [CNN 아키텍처 발전사](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)
7. [실전 활용 및 최적화](https://www.notion.so/25a486f8d887809da1ddd8b29ae0d5d3?pvs=21)

---

## CNN(Convolutional Neural Network)

### 합성곱 신경망(CNN)이란?

이미지 처리에 특화된 딥러닝 모델.

인간의 시각 피질 구조에서 영감을 받아 개발, **지역적 특징을 효과적으로 추출**할 수 있는 것이 핵심

### CNN의 핵심 아이디어

- **지역적 연결성(Local Connectivity)**: 전체 이미지가 아닌 작은 영역(receptive field)에 집중
- **매개변수 공유(Parameter Sharing)**: 같은 필터를 전체 이미지에 재사용하여 효율성 증대
- **평행 이동 불변성(Translation Invariance)**: 객체의 위치가 바뀌어도 동일하게 인식

---

## CNN의 기본 구조

`Input Image → [Convolution + Activation] → Pooling → ... → Fully Connected → Output`

CNN은 크게 **특징 추출 부분**과 **분류 부분**으로 나뉨

### 1. 특징 추출 부분 (Feature Extraction)

- **Convolution Layer**: 이미지에서 특징을 추출(특징 맵 생성)
- **Activation Function**: 비선형성 추가
- **Pooling Layer**: 특징맵 크기 축소 및 중요한 정보 선별

### 2. 분류 부분 (Classification)

- **Fully Connected Layer**: 추출된 특징을 바탕으로 최종 예측

---

## Convolution Layer 상세

### 합성곱 연산의 원리

합성곱 연산은 이미지를 분석하는 가장 기본적인 과정

필터를 입력 이미지 위에서 슬라이딩하면서 내적을 계산하는 과정

- **필터(Filter/Kernel):** 특정 패턴(예: 수평선, 수직선, 대각선 등)을 찾는 작은 창문
- **슬라이딩(Sliding):** 이 필터를 입력 이미지 위에서 한 칸씩 이동
- **내적(Dot Product):** 이동한 필터와 이미지의 겹치는 부분의 픽셀 값들을 서로 곱해서 모두 더함

이 과정을 거치면 이미지의 어느 부분에 필터가 찾고자 하는 패턴이 있는지 점수로 나타남

### 주요 매개변수들

### 1. 필터(Filter/Kernel)

- **역할**: 특정 패턴을 감지
- **크기**: 보통 3×3, 5×5, 7×7 사용
- **개수**: 출력 채널의 수를 결정

### 2. 스트라이드(Stride)

- **정의**: 필터가 이동하는 간격
- **효과**:
    - Stride = 1: 세밀한 특징 추출
    - Stride > 1: 특징맵 크기 감소, 계산량 절약

### 3. 패딩(Padding)

- **목적**: 특징맵 크기 조절 및 경계 정보 보존
- **종류**:
    - Zero Padding: 0으로 채움
    - Same Padding: 입력과 출력 크기 동일 유지
    - Valid Padding: 패딩 없음

### 출력 크기 계산 공식

`출력 크기 = (입력 크기 - 필터 크기 + 2×패딩) ÷ 스트라이드 + 1`

### 매개변수 수 계산

`매개변수 수 = (필터 높이 × 필터 너비 × 입력 채널 수 + 1) × 출력 채널 수`

---

## Activation Function

### 활성화 함수의 필요성

Convolution 연산만으로는 **선형 변환**만 가능, 복잡한 패턴을 학습하기 위해 **비선형성**을 추가

### 주요 활성화 함수들

### 1. ReLU (Rectified Linear Unit)

- **수식**: f(x) = max(0, x)
- **장점**:
    - 계산이 간단하고 빠름
    - Vanishing Gradient 문제 완화
    - 스파스 활성화로 효율적
- **단점**: Dead ReLU 문제 (음수 입력시 항상 0)

### 2. Leaky ReLU

- **수식**: f(x) = max(αx, x) (α는 작은 양수, 보통 0.01)
- **장점**: Dead ReLU 문제 해결
- **단점**: α 값 설정 필요

### 3. ELU (Exponential Linear Unit)

- **수식**: f(x) = x (x > 0), α(e^x - 1) (x ≤ 0)
- **장점**: 음수 영역에서도 정보 전달, 평균 0에 가까운 출력

### 4. Swish/SiLU

- **수식**: f(x) = x × sigmoid(x)
- **특징**: 최근 많이 사용되는 함수, 매끄러운 비선형성

---

## Pooling Layer

### Pooling의 목적

1. **특징맵 크기 축소**: 계산량 감소 및 과적합 방지
2. **위치 불변성 증가**: 작은 위치 변화에 강건
3. **Receptive Field 확장**: 더 넓은 영역의 정보 통합

### Pooling 종류

### 1. Max Pooling

- **방법**: 지정된 영역에서 최댓값 선택
- **특징**: 가장 강한 특징 보존, 노이즈에 강함
- **용도**: 일반적으로 가장 많이 사용

### 2. Average Pooling

- **방법**: 지정된 영역의 평균값 계산
- **특징**: 부드러운 특징 추출, 전반적 정보 보존
- **용도**: Global Average Pooling으로 분류층 대체

### 3. Global Average Pooling (GAP)

- **방법**: 전체 특징맵의 평균값 계산
- **장점**: 매개변수 수 대폭 감소, 과적합 방지
- **용도**: 최종 분류층 직전에 사용

---

## CNN 아키텍처 발전사

### 1. LeNet-5 (1998)

- **특징**: 최초의 성공적인 CNN
- **구조**: Conv → Pool → Conv → Pool → FC
- **용도**: 손글씨 숫자 인식

### 2. AlexNet (2012)

- **혁신**:
    - ReLU 활성화 함수 사용
    - Dropout 정규화 기법
    - GPU 활용한 병렬 처리
- **성과**: ImageNet 대회 우승, 딥러닝 부흥의 시작점

### 3. VGGNet (2014)

- **특징**:
    - 3×3 작은 필터만 사용
    - 네트워크 깊이 증가 (16, 19층)
    - 간단하고 균일한 구조

### 4. GoogLeNet/Inception (2014)

- **혁신**:
    - Inception 모듈로 다양한 크기의 필터 병렬 사용
    - 1×1 컨볼루션으로 차원 축소
    - Global Average Pooling 사용

### 5. ResNet (2015)

- **핵심**: Residual Connection (Skip Connection)
- **해결**: Vanishing Gradient 문제 해결
- **성과**: 매우 깊은 네트워크 (152층) 훈련 가능

### 6. DenseNet (2017)

- **특징**: 모든 층이 연결된 Dense Connection
- **장점**: 특징 재사용, 매개변수 효율성

### 7. EfficientNet (2019)

- **혁신**: Compound Scaling (폭, 깊이, 해상도 동시 조절)
- **성과**: 적은 매개변수로 높은 성능 달성

---

## 실전 활용 및 최적화

### 1. 데이터 전처리

- **정규화**: 픽셀 값을 [0,1] 또는 [-1,1] 범위로 조정
- **데이터 증강**: 회전, 뒤집기, 크롭, 색상 변환 등
- **평균 차감**: ImageNet 평균값으로 정규화

### 2. 모델 설계 팁

- **필터 크기**: 3×3을 기본으로, 필요시 1×1, 5×5 사용
- **채널 수**: 32 → 64 → 128 → 256 순으로 2배씩 증가
- **깊이 vs 폭**: 일반적으로 깊게 만드는 것이 효과적

### 3. 훈련 기법

- **배치 정규화**: 각 층의 입력을 정규화하여 훈련 안정화
- **드롭아웃**: 과적합 방지를 위한 정규화 기법
- **학습률 스케줄링**: 훈련 과정에서 학습률 조절

### 4. 최적화 기법

- **옵티마이저**: Adam, AdamW, RMSprop 등 사용
- **학습률**: 0.001부터 시작하여 점진적 감소
- **웨이트 초기화**: He 초기화, Xavier 초기화 등

### 5. 성능 향상 기법

- **앙상블**: 여러 모델의 예측 결합
- **테스트 타임 증강**: 추론시 여러 증강된 이미지로 예측
- **모델 압축**: 지식 증류, 양자화, 프루닝 등

### 6. 전이 학습 (Transfer Learning)

- **사전 훈련된 모델**: ImageNet으로 훈련된 모델 활용
- **파인 튜닝**: 마지막 몇 층만 재훈련
- **특징 추출**: 사전 훈련된 가중치 고정 후 분류기만 훈련

---

### **CNN 핵심 모델 자료집**

| 모델 | 핵심 아이디어 | 모델의 의의 |
| --- | --- | --- |
| **AlexNet** (2012) | **GPU 활용, ReLU 활성화 함수** | 딥러닝 부흥의 시작. GPU를 사용해 대규모 데이터 학습의 가능성을 열었고, ReLU를 도입해 깊은 신경망의 학습 문제를 완화함. |
| **VGGNet** (2014) | **'작은 필터, 깊은 네트워크'** | `3x3` 필터만을 반복적으로 사용해 모델의 **깊이(Depth)**가 성능에 얼마나 중요한지 증명. 이후 모델 설계의 기본이 됨. |
| **ResNet** (2015) | **잔차 연결(Residual Connection),    보틀넥 계층 활용** | 기울기 소실 문제를 해결하며 층을 수백 개까지 쌓을 수 있게 함. **깊이의 한계를 돌파**하며 인간의 인식 능력을 뛰어넘음. |
| **EfficientNet** (2019) | **복합 스케일링(Compound Scaling), MBConv 블록**을 사용해 효율성을 극대화 | **'효율성'**을 극대화. 깊이, 너비, 해상도를 최적의 비율로 확장해 적은 연산량으로도 높은 정확도를 달성함. |

---

### **모델 발전의 역사적 흐름**

이 네 가지 모델은 CNN의 발전 과정을 보여주는 완벽한 예시

- **AlexNet**이 "딥러닝도 할 수 있다"는 가능성을 보여줬고,
- **VGGNet**은 "모델을 깊게 만들수록 좋다"는 방향을 제시,
- **ResNet**은 "아무리 깊어도 학습할 수 있다"는 것을 증명하며 깊이의 한계를 뛰어넘음
- **EfficientNet**은 "무작정 깊고 큰 것만이 능사가 아니다. 효율성이 중요하다"는 새로운 화두를 던짐

### **MBConv 블록 핵심 요소**

1.효율적인 연산

| 요소 | 역할 |
| --- | --- |
| **깊이별 합성곱 (Depthwise Conv)** | 각 채널에 필터 1개씩 적용. 연산량과 매개변수를 크게 줄여 효율성을 높임 |
| **포인트별 합성곱 (Pointwise Conv)** | `1x1` 필터를 사용해 채널 간 정보를 섞어주고, 최종적으로 채널 수를 조절 |
| **역전된 보틀넥 (Inverted Bottleneck)** | 채널 수를 **먼저 늘리고(1×1 Conv)**, 깊이별 합성곱을 거친 후 **다시 줄이는(1×1 Conv)** 구조. 모델의 표현력을 높임 |

2.**학습 안정성**

잔차 연결
MBConv 블록도 ResNet처럼 **잔차 연결을 사용**

3.**성능 향상**
Swish**활성화 함수:** `Swish`라는 특별한 활성화 함수를 사용. `ReLU`보다 더 좋은 성능
**Squeeze and Excitation:** 채널별로 중요도를 조절하는 **어텐션(Attention)** 메커니즘
모델이 더 중요한 특징에 집중하도록 함

베이스라인 모델 스케일링
모델의 성능을 높이기 위해 **깊이, 너비, 해상도**를 각각 조절하는 일반적인 방법

|             구분 |                                                              설명 |
| --- | --- |
| **깊이(Depth)** | 모델의 층(layer) 수를 늘려 성능을 높이는 방법 |
| **너비(Width)** | 모델의 채널 수를 늘려 이미지의 미세한 특징을 더 잘 담는 방법 |
| **해상도(Resolution)** | 입력되는 이미지의 해상도를 높여서 모델이 더 선명하고 세밀한 특징을 파악하게 하는 방법 |

컴파운드 스케일링

**EfficientNet** 모델에서 사용하는 특별한 스케일링 방법

베이스라인 스케일링이 재료를 하나씩 따로따로 넣는 거라면, 

**컴파운드 스케일링은 깊이, 너비, 해상도 세 가지를 하나의 비율로 묶어서 동시에 조절**

성능을 가장 효율적으로 끌어올릴 수 있음

### **1단계: 스케일링 계수 (α, β, γ) 찾기**

- **목표:** 모델의 깊이, 너비, 해상도를 얼마나 늘릴지 결정하는 최적의 비율을 찾는 단계
- **과정:** 기준 모델인 **EfficientNet-B0**를 사용
- **방법:** **ϕ(파이)** 값을 **1로 고정**하고, 여러 실험을 통해 가장 효율적인 **α, β, γ** 조합을 찾기
- **결과:** 논문에서는 **α=1.2, β=1.1, γ=1.15**라는 값을 찾.

### **2단계: ϕ(파이)를 이용해 모델 확장하기**

- **목표:** 1단계에서 찾은 비율을 유지하면서 모델 전체 크기를 키우는 단계
- **과정:** **α, β, γ**는 1단계에서 찾은 값으로 **고정**
- **방법:** **ϕ** 값만 1, 2, 3...으로 바꿔가면서 모델의 깊이, 너비, 해상도를 동시에, 그리고 **가장 효율적인 비율로** 키우기
- **결과:** **ϕ**가 커질수록 EfficientNet-B1, B2, B3...처럼 더 큰 모델이 만들어짐
