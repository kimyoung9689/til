# 컴퓨터비전 제너레이션

데이터를 분류하고 판별하는 기존의 컴퓨터 비전 기술과 달리,

데이터의 규칙을 학습해 새로운 시각적 데이터를 창조하는 역할

생성 모델

데이터를 보고 학습해서, 

기존에는 없던 새로운 데이터를 만들어내는 인공지능 모델

생성 모델의 핵심은 패턴 학습. 

수많은 고양이 사진을 보여주면, 

모델은 고양이의 눈, 코, 귀, 털 무늬 같은 특징들을 학습

주요 생성 모델 종류

GAN (Generative Adversarial Network)

**원리:** 생성자와 판별자라는 두 모델이 서로 경쟁하며 학습
**과정:** 생성자는 진짜 같은 가짜 이미지를 만들고, 판별자는 진짜와 가짜를 구별하려고 노력
**특징:** 학습이 불안정하고 어렵지만, 이미지를 빠르게 생성하고 특정 스타일을 바꾸는 데 유용

Diffusion Model (확산 모델)

**원리:** 이미지에 점진적으로 노이즈(잡음)를 추가하는 과정을 학습하고, 반대로 노이즈를 제거해서 원래 이미지를 복원하는 방법
**과정:** 이미지를 만들 때는 노이즈가 가득한 상태에서 시작해, 학습한 방법대로 노이즈를 조금씩 제거
**특징:** 매우 정교하고 고품질의 이미지

---

| 구분 | 판별 모델 (Discriminative Model) | 생성 모델 (Generative Model) |
| --- | --- | --- |
| **학습 과정** | 데이터의 **분류 경계**를 학습 | 데이터 **분포**를 학습 |
| **확률 모델** | p(Y|X) |  p(X) 또는 p(X|Y) |
| **활용 분야** | 객체 분류, 객체 검출, 이상치 탐지 | 데이터 생성, 신호 품질 개선, 이미지 인페인팅 |

### 두 모델의 가장 큰 차이점은 **목표와 학습 방식**

판별 모델 (Discriminative Model)

**데이터를 분류하고 판별**하는 데 특화
주어진 데이터가 어떤 종류인지 경계선을 찾아 판단하는 역할

생성 모델 (Generative Model)

**데이터의 분포(규칙)를 학습해서 새로운 데이터를 만들어내는** 데 특화
주어진 데이터를 통해 데이터 분포를 학습

---

### 가능도 (Likelihood)

주어진 모델에서 관측된 데이터가 나타날 확률

모델이 얼마나 데이터를 잘 설명하는지를 나타내는 값

**예시:** 앞면이 나올 확률이 80%인 동전이 있다고 가정 

이 동전을 10번 던져서 앞면이 7번 나왔다. 

이때 앞면 7번이라는 결과에 대한 이 동전 모델의 가능도를 계산할 수 있다. 

이 값이 높을수록, 모델이 우리가 관측한 결과를 더 잘 설명한다고 볼 수 있다.

최대가능도 추정(MLE)은 바로 이 **가능도를 가장 크게 만드는 모델을 찾는 방법**

### 로그 가능도 (Log-Likelihood)

말 그대로 **가능도에 로그를 씌운 값**

가능도를 사용하지 않고 굳이 로그를 씌우는 이유는 두 가지가 있다.

1. **계산의 편리성:** 여러 데이터의 가능도를 곱해야 할 때, 로그를 씌우면 곱셈이 덧셈으로 바뀌어. 이는 컴퓨터 계산에서 오버플로우(overflow)나 언더플로우(underflow) 같은 수치적인 문제를 방지하고, 계산을 훨씬 안정적으로 만들어 줘.
2. **단조 증가 함수:** 로그 함수는 값이 증가할수록 함수 값도 증가하는 **단조 증가 함수**의 특성을 가지고 있어. 이 덕분에 가능도를 최대로 만드는 지점(매개변수)은 로그 가능도를 최대로 만드는 지점과 동일해. 따라서 로그를 씌워도 우리가 찾아야 하는 최종적인 답은 변하지 않아.

그래서 실제 머신러닝 모델을 학습할 때는 가능도 자체를 사용하는 대신, 로그를 씌운 **로그 가능도**를 사용해서 최적의 매개변수를 찾아.

### 간단한 정리

- **가능도:** 모델이 데이터를 얼마나 잘 설명하는지 나타내는 '확률' 값.
- **로그 가능도:** 계산의 편리성과 안정성을 위해 가능도에 로그를 취한 값.
- **최대가능도 추정:** 로그 가능도가 가장 커지는 지점을 찾아, 가장 이상적인 모델을 만드는 방법.

### 최대가능도 추정(Maximum Likelihood Estimation, MLE)

관측된 데이터가 가장 잘 나타날 수 있도록 만드는 모델의 매개변수를 찾는 방법

우리가 던진 동전이 10번 중 7번 앞면이 나왔다고 가정

앞면이 나올 확률이 50%인 공정한 동전일까?

아니면 앞면이 나올 확률이 80%인 조작된 동전일까?

최대가능도 추정은 이런 결과(10번 중 7번 앞면)가 나올 확률이 가장 높은 동전은 무엇인가? 라는 질문에 답하는 방법

주어진 데이터가 가장 그럴듯하게 나타나도록 하는 모델의 확률(매개변수)을 찾기

### 작동 방식

1. **가정하기:** 먼저 우리가 가진 데이터가 어떤 확률 분포를 따른다고 가정 

        (예: 동전 던지기는 베르누이 분포를 따른다.)

1. **가능도 계산:** 각 매개변수(동전의 앞면 확률) 값에 대해, 우리가 관측한 데이터가 나올 확률을 계산. 이 확률을 가능도(Likelihood) 라고 부름
2. **최대값 찾기:** 여러 매개변수 값들을 바꿔가면서 계산한 가능도 중에서 가장 큰 값을 가지는 매개변수를 찾기. 바로 그 매개변수가 우리가 찾는 최대가능도 추정치

### 생성 모델과의 관계

최대가능도 추정은 생성 모델에서 매우 중요한 개념

- **생성 모델의 목표:** 데이터의 분포를 학습해서 새로운 데이터를 만들어내는 것
- **MLE의 역할:** 생성 모델이 데이터의 분포를 잘 학습했는지 평가하거나, 학습 과정 자체를 이끌어주는 역할을 함. 모델이 만들어낸 분포가 실제 데이터의 분포와 가장 비슷하도록 모델의 매개변수를 조정하는 데 사용

요약하자면, **최대가능도 추정은 주어진 데이터로부터 가장 '그럴듯한' 모델을 찾아내는 통계적인 방법**이며, 이는 생성 모델이 실제 데이터와 비슷한 가짜 데이터를 만들 수 있도록 돕는 핵심 원리 중 하나

### VAE(변분 오토인코더)

이미지를 압축하고 다시 복원하는 과정
이 과정을 담당하는 것이 **인코더**와 **디코더**

**인코더:** 입력 이미지를 받아 이미지의 핵심적인 특징을 담은 압축된 정보로 변환

복잡한 이미지 데이터를 단순한 '숫자 묶음'으로 만듦

**잠재 공간 (Latent Space):** 인코더가 만들어낸 압축된 벡터들이 모인 가상 공간

이 공간의 각 점들은 하나의 이미지를 나타낸다. 

예) 잠재 공간에서 서로 가까운 점들은 비슷한 이미지를 나타내고, 

멀리 떨어진 점들은 완전히 다른 이미지를 나타냄 

VAE의 목표 중 하나는 이 잠재 공간을 부드럽게 만드는 것

**디코더:** 잠재 공간에 있는 벡터를 받아서, 다시 원래의 이미지 형태로 복원하는 역할이 과정에서 잠재 공간의 정보를 바탕으로 새로운 이미지를 생성할 수 있음

### KL 발산

쿨백-라이블러 발산(Kullback-Leibler Divergence), 줄여서 **KL 발산**

**두 확률 분포가 얼마나 다른지**를 측정하는 지표

쉽게 말해, 우리가 만든 모델의 분포와 실제 데이터의 분포가 얼마나 차이가 나는지 계산하는 것. 이 값이 **작을수록** 두 분포가 비슷하다는 뜻

VAE 학습의 목표는 인코더가 만들어낸 **잠재 공간의 분포**와 

우리가 미리 정해둔 **정규 분포**의 KL 발산을 최소화하는 것

발산 값이 최소화되면 두 분포가 비슷해져서, 인코더가 잠재 공간의 정보를 정규 분포처럼 균일하고 예측 가능한 형태로 배열하게 됨

### KL 발산이 최소화되면 어떻게 될까?

VAE의 가장 큰 장점인 새로운 데이터 생성 능력이 극대화 됨

1. **잠재 공간의 부드러운 연결:** 잠재 공간이 정규 분포처럼 부드럽게 배열되면, 이 공간의 어느 한 지점을 임의로 찍더라도 디코더가 이를 자연스러운 이미지로 복원할 수 있게 됨. 만약 잠재 공간이 엉망이라면, 중간에 있는 지점은 의미 없는 이미지를 만들어낸다.
2. **데이터의 원활한 보간:** 잠재 공간에서 두 이미지에 해당하는 점을 선택하고, 그 사이의 경로를 따라가면서 디코더로 이미지를 생성하면, 한 이미지가 다른 이미지로 점진적으로 변해가는 부드러운 과정을 볼 수 있다. 이건 잠재 공간이 정규 분포처럼 잘 정리되어 있기 때문에 가능한 일

요약하면, **KL 발산 최소화는 VAE가 새로운 이미지를 안정적이고 부드럽게 만들어낼 수 있는 핵심적인 조건**이라고 할 수 있다.

---

### 판별 모델과 생성 모델의 평가 지표

1. 판별 모델의 평가 (쉬운 이유)

정답이 존재하기 때문에 평가가 비교적 쉬움

- **분류 문제:** 예측한 범주와 실제 범주를 비교해서 평가. 정확도를 주로 쓰지만, 데이터가 불균형할 때는 정밀도, 재현율, F-점수 같은 지표를 함께 사용해 보완
- **회귀 문제:** 예측값과 실제값의 차이를 기반으로 평가. 대표적인 지표로는 평균 제곱 오차(MSE)와 평균 절대 오차(MAE) 등이 있다.

 2. 생성 모델 평가 (어려움)

생성 모델은 판별 모델과 달리,

**비교할 정답이 없기 때문에** 평가가 어렵다.

델이 단순히 훈련 데이터를 외워서 복사하는 현상이 생길 수 있고, 

생성된 결과물에 대한 **사람의 주관적인 판단**이 개입될 수 있기 때문

1. 생성 모델의 평가 기준

따라서 생성 모델은 주관적인 판단을 배제하고 연구자들이 객관적으로 공감할 수 있는 지표를 활용

핵심 평가 기준은 두 가지

**품질 (Fidelity):** 생성된 이미지가 얼마나 현실적이고 고품질인지

**다양성 (Diversity):** 생성된 이미지가 얼마나 다양한지
이러한 기준을 바탕으로, 
**FID(Fréchet Inception Distance)** 같은 다양한 평가 지표가 제안되고 사용

---

### 생성 모델의 평가 지표 (IS & FID)

### Inception Score (IS)

생성된 이미지를 다른 모델(Inception V3)로 분류해서 점수를 매기는 방식

**계산 방법:**

- 생성된 이미지의 확률 분포가 특정 클래스에 대해 **편향되어 있을수록** 점수가 높아짐(충실도를 나타냄)
- 모든 생성 이미지의 분포가 **균일할수록** 점수가 높아짐(다양성을 나타냄)

**장점:** 이미지 품질과 다양성을 하나의 지표로 동시에 평가
**단점:** IS를 계산할 때 사용한 Inception V3 모델이 인식할 수 없는 클래스(예: 사람 얼굴)에 대해서는 제대로 평가할 수 없다는 한계가 있

### Fréchet Inception (FID)

**실제 이미지 데이터셋과 생성된 이미지 데이터셋의 분포가** 

**얼마나 비슷한지**를 측정하는 지표
IS보다 더 나은 평가 지표로 여겨짐

- **계산 방법:** 실제 데이터와 생성된 데이터의 분포를 각각 **정규 분포**로 가정하고, 두 분포 사이의 거리를 계산.

       이 거리가 **가까울수록** 더 좋은 모델

- **장점:** IS의 단점인 이미지 다양성을 제대로 평가하지 못하는 문제를 보완하고, 이미지의 품질과 다양성을 동시에 더 잘 평가할 수 있다.
- **단점:** FID는 충실도와 다양성을 함께 평가하기 때문에, 모델이 품질에 치중했는지 다양성에 치중했는지 각각의 특성을 따로 평가할 수 없다는 한계가 있다.

IS를 계산할 때 반드시 **nception V3** 모델을 사용해야 하는 건 아님
하지만 일반적으로는 Inception V3 모델을 가장 많이 사용

---

### 평가 지표의 필요성

기존의 FID는 생성된 이미지의 품질과 다양성을 동시에 평가하기 때문에, 

모델이 품질에 치중했는지, 다양성에 치중했는지 각각을 판단할 수 없는 한계 있음

 그래서 품질과 다양성을 각각 평가할 수 있는 지표가 필요해짐

---

### 판별 모델에서의 P&R

- **정밀도**: 모델이 **양성**이라고 예측한 것 중에서, **실제로 양성**인 것의 비율.

       예) "강아지"라고 예측한 사진 중 실제로 강아지인 사진의 비율을 측정

- **재현율**: **실제로 양성**인 것 중에서, 모델이 **양성**이라고 정확히 예측한  비율.

       예) 실제 강아지 사진들 중에서 모델이 강아지라고 찾아낸 사진의 비율을 측정

---

### 생성 모델에서의 P&R

판별 모델의 개념을 생성 모델에 맞게 변형한 것이 

개선된 정밀도(Improved Precision)와 재현율(Improved Recall)

- **개선된 정밀도**: 생성된 데이터 중에서 실제 데이터 분포에 아주 가까운 데이터의 비율을 측정. 이는 생성된 이미지의 품질을 평가하는 지표로 사용
- **개선된 재현율**: 실제 데이터 중에서 생성된 데이터 분포에 아주 가까운 데이터의 비율을 측정해. 이는 **생성 모델의 다양성(Diversity)**을 평가하는 지표로 사용돼.

**정밀도/재현율**은 **예측 능력**을 평가하는 지표이고, 

**개선된 정밀도/재현율**은 **창조 능력**을 평가하는 지표

---

### 한계점

이러한 개선된 평가 지표들 역시 몇 가지 한계점을 가지고 있다.

- **이상치에 민감**

        데이터 몇 개의 위치만 변해도 평가 점수가 크게 변할 수 있어 지표가 불안정

- **샘플링에 따라 점수 변동**: 실제와 생성된 데이터 분포가 완벽하게 일치하더라도, 샘플링 방식에 따라 점수가 낮게 나올 수 있다는 문제점
- **높은 계산량**: 매번 생성된 데이터의 분포를 알아내고 근접한 데이터들을 계산해야 해서 계산량이 많다.

결론적으로, 정밀도와 재현율은 생성 모델의 **품질과 다양성**을 각각 평가할 수 있는 지표이지만, 여전히 불안정하고 계산량이 많다는 한계가 있다.

---

### 조건부 vs. 일반 생성 모델

- **일반 생성 모델:** 데이터의 분포 `p(X)`를 학습하며, 생성되는 데이터의 의미를 제어할 수 없음
- **조건부 생성 모델:** 레이블 `Y`가 주어졌을 때 데이터의 분포 `p(X|Y)`를 학습해서, 특정 조건(예: 특정 숫자, 스타일 등)을 만족하는 데이터를 생성할 수 있음

### 조건부 모델 평가 지표의 필요성

기존의 IS나 FID는 생성된 이미지의 품질과 다양성만 평가할 뿐, 

**특정 조건에 맞게 이미지가 생성되었는지**는 고려하지 못하는 한계가 있음

문제 해결을 위한 지표

**Intra FID (Intra-class FID):** 특정 클래스 내의 실제 이미지와 해당 클래스를 조건으로 생성된 이미지 간의 FID를 계산하는 지표

**전 훈련된 분류기의 정확도:** 사전 훈련된 분류기를 사용해서, 생성된 이미지가 주어진 조건(레이블)에 얼마나 잘 부합하는지 정확도를 측정

이 지표는 사전 훈련된 분류기에 크게 의존

**CAS (Classification Accuracy Score):** 생성된 데이터를 사용해서 분류기를 학습하고, 그 분류기가 실제 테스트 데이터를 얼마나 잘 분류하는지를 측정
이는 사전 훈련된 분류기 정확도와 반대 과정

**LPIPS (Learned Perceptual Image Patch Similarity):** 사전 훈련된 분류기의 특성 사이의 유사도를 측정하여 두 이미지의 유사도를 평가하는 지표
인간의 시각적 인지 능력과 유사하게 작동

**CLIP Score:** 텍스트-이미지 관계를 학습한 CLIP 모델을 활용
생성된 이미지가 입력된 텍스트와 얼마나 유사한지 측정하는 지표

---

### 오토 인코더(Autoencoder)

입력 데이터의 패턴을 학습해서 데이터를 다시 복원하는 모델

**비선형 차원 축소** 기법으로도 활용

**구조:** 오토 인코더는 크게 두 부분으로 나뉜다.

- **인코더:** 입력 데이터를 받아 저차원의 잠재 표현으로 요약하는 역할
- **디코더:** 이 잠재 표현을 받아서 원래의 데이터를 다시 복원(재구성)하는 역할

**학습 방법:** 입력 데이터와 디코더가 복구한 출력 데이터 간의 차이(손실)를 줄이는 방식으로 학습
주로 평균 제곱 오차(MSE)를 손실 함수로 사용

### 디노이징 오토 인코더

**원리:** 입력 데이터에 일부러 **랜덤 노이즈를 주입**한 다음, 이 노이즈를 제거하고 원래의 깨끗한 데이터로 복원하도록 학습

**효과:** 이 과정에서 모델은 데이터의 핵심적인 특성을 더 정확하게 학습하게 되고, 노이즈에 강한 강건한 잠재 표현을 만들 수 있다.

### 오토 인코더의 활용

- **특징 추출:** 학습이 완료된 오토 인코더의 **인코더 부분**만 떼어내서 특징 추출기로 활용. 추출된 잠재 벡터는 분류나 클러스터링 같은 다른 머신러닝 문제 해결에 사용
- **이상치 탐지:** 모델은 정상적인 데이터의 패턴은 잘 복원하지만, 학습하지 않은 이상치는 제대로 복원하지 못함
- 따라서 이상치를 복원했을 때

       **평균 제곱 오차가 크게** 나오므로, 이를 기준으로 이상치를 판단
