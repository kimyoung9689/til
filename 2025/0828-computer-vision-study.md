# 컴퓨터비전

컴퓨터가 사람처럼 이미지를 보고 이해하게 만드는 기술

**픽셀**: 이미지를 구성하는 가장 작은 점.  픽셀들이 모여 하나의 이미지를 만든다.
**색상 채널**: 컬러 이미지는 보통 빨강(R), 초록(G), 파랑(B) 세 가지 채널로 구성
**기본 이미지 처리**: 이미지 흑백으로 바꾸기, 크기 조절, 밝기 조절 등

---

### Low-level (기초 단계)

- **목표**: 이미지의 **픽셀** 자체를 다루거나, 단순한 시각적 특징을 찾는 단계
- **주요 기술**:
    - **컬러 변환**: 이미지를 흑백으로 바꾸거나, RGB 색상을 다른 형식으로 변환.
    - **블러링(Blurring)**: 이미지를 흐릿하게 만들어 잡음을 줄임.
    - **엣지 검출(Edge Detection)**: 이미지에서 물체의 경계선(모서리, 선)을 찾아내는 기술. **Canny 엣지 검출**이 대표적

---

### Mid-level (중간 단계)

- **목표**: Low-level 기술로 찾은 특징들을 **의미 있는 그룹**으로 묶거나, 이미지의 일부분을 분석
- **주요 기술**:
    - **특징점 매칭**: 여러 이미지에서 공통된 특징점들을 찾아내는 기술. **SIFT**나 **SURF** 알고리즘이 유명
    - **영상 분할(Segmentation)**: 이미지를 여러 영역으로 나누는 것. 예를 들어, 사진에서 하늘, 땅, 사람을 각각 다른 영역으로 구분하는 작업.
    - **이미지 복원/변형**: 흐릿한 이미지를 선명하게 만들거나, 왜곡된 이미지를 바로잡는 기술.

---

### High-level (응용 단계)

- **목표**: 이미지를 사람처럼 **이해하고 분석**하는 단계야. 딥러닝 기술이 주로 사용
- **주요 기술**:
    - **이미지 분류(Image Classification)**: 이미지가 어떤 종류인지 판별하는 기술. (예: 사진 속 동물이 고양이인지 개인지)
    - **객체 탐지(Object Detection)**: 이미지에서 물체의 종류와 위치(사각형)를 동시에 찾아내는 기술. **YOLO**가 여기에 속해.
    - **얼굴 인식**: 사람의 얼굴을 찾고, 그 사람이 누구인지 식별하는 기술.
    - **자세 추정(Pose Estimation)**: 사람의 관절 위치를 파악해서 어떤 자세를 취하고 있는지 추정하는 기술.

---

# 고전 컴퓨터 비전

**사람이 직접 이미지의 특징을 찾아내고, 그 특징을 기반으로 규칙을 정의하여 이미지를 분석**하는 기술

컴퓨터가 이미지를 보고 이해하도록 하는 기술로, 딥러닝이 나오기 전에 주로 쓰이던 방식

### 고전 컴퓨터 비전과 현대/일반 컴퓨터 비전의 차이

가장 큰 차이는 **'특징 추출'을 누가 하느냐**

고전은 사람이 직접, 현대는 컴퓨터가 알아서

| 구분 | 고전 컴퓨터 비전 | 현대/일반 컴퓨터 비전 (딥러닝 기반) |
| --- | --- | --- |
| **핵심 원리** | **규칙 기반**<br>(Rule-based) | **데이터 학습 기반**<br>(Data-driven) |
| **특징 추출** | **사람이 수동으로**<br>코딩을 통해 특징(엣지, 코너 등)을 직접 찾아냄. | **컴퓨터가 자동으로**<br>신경망이 스스로 특징을 학습하고 추출함. |
| **주요 기술** | OpenCV 등 규칙 기반 알고리즘, SVM 등 전통적인 머신러닝 | **딥러닝 신경망 (DNN, CNN)** |
| **인식 정확도** | 조건에 따라 편차가 크고, 한계가 명확함. | 방대한 데이터가 있다면 매우 높고 유연함. |

## 고전 컴퓨터비전 언제 쓰이나?

딥러닝이 못하거나, 굳이 딥러닝을 쓸 필요 없는 상황

1. **딥러닝으로 해결하기 어려운 문제**:
    - **데이터가 부족할 때**: 딥러닝은 엄청난 양의 데이터가 필요하지만, 고전 비전은 상대적으로 적은 데이터로도 특정 규칙을 적용해 문제 해결 가능
    - **실시간 처리가 중요할 때**: 로봇 공학이나 자율 주행처럼 빠른 속도로 연산해야 하는 경우, 가벼운 고전 알고리즘이 복잡한 딥러닝 모델보다 유리함.
    
            예) 로봇이 주변 환경을 인식하고 경로를 짜는 데는 **점군** 처리 같은 고전 방식이 주로 쓰임.
    
    ---
    
2. **딥러닝 모델 결과의 후처리**:
    - 딥러닝이 물체를 감지한 후에, 그 결과물을 더 정교하게 다듬는 데 고전 비전 기술이 쓰임.
    
           예) 딥러닝 모델이 대략적인 사각형으로 핸드폰을 찾으면, **컨투어 검출** 같은 고전 알고리즘으로 핸드               폰의 정확한 외곽선을 딴다.
    
3. **가볍고 빠른 처리가 필요할 때**:
    - 단순한 작업이나 저사양 기기에서 이미지를 처리해야 할 때, 딥러닝 모델을 처음부터 만들고 학습시킬 필요 없이 고전 비전 기술만으로도 충분히 효과를 낼 수 있다.
    
           **이로전, 딜레이션** 같은 **모폴로지 변환**은 계산량이 매우 적어서 가벼운 작업에 최적화됨
    
    - 작은 노이즈를 제거, 이미지의 특정 영역만 단순하게 강조할 때도 고전 비전이 효율적

### 1. 기초: 이미지 처리

**이미지의 기본**: 컴퓨터에게 이미지는 픽셀이라는 작은 점들이 모여있는 숫자들의 배열
흑백 이미지는 0~255 사이의 숫자로 밝기를 나타내고, 

컬러 이미지는 빨강, 초록, 파랑(RGB) 세 가지 숫자로 색을 표현

**필터링**: 이미지에 필터(커널)를 적용해서 이미지를 변형

- **블러링(Blurring)**: 이미지를 부드럽게 만들어서 노이즈를 줄임
- **샤프닝(Sharpening)**: 이미지를 더 선명하게 만든다.

**형태학적 연산 (Morphological Operations)**: 이미지를 팽창시키거나 침식시켜 모양을 변형

- **이로전(Erosion)**: 경계를 깎아서 물체를 축소하고 노이즈를 제거
- **딜레이션(Dilation)**: 경계를 넓혀서 물체를 확장하고 끊어진 부분을 이어줌
- **오프닝(Opening)**: **이로전 후 딜레이션**. 작은 노이즈를 없애는 데 사용
- **클로징(Closing)**: **딜레이션 후 이로전**. 물체 내부의 작은 구멍을 메움
- **형태학적 기울기(Morphological gradient)**: 딜레이션 결과에 이로전 결과를 빼 **물체의 경계선만 추출**
- 탑 햇(Top hat): 원본 이미지에서 오프닝 결과를 빼서 **이미지의 밝은 노이즈**를 분리

| 구분 | 개념 | 동작 | 주요 용도 |
| --- | --- | --- | --- |
| **이로전 (Erosion)** | 경계 침식 연산 | **흰색(1) 영역을 축소**시켜. 커널 아래 0이 하나라도 있으면 가운데 픽셀을 0으로 만든다. | - 작은 노이즈 제거<br>- 서로 붙은 물체 분리 |
| **딜레이션 (Dilation)** | 경계 팽창 연산 | **흰색(1) 영역을 확장**시켜. 커널 아래 1이 하나라도 있으면 가운데 픽셀을 1로 만든다. | - 끊어진 물체 연결<br>- 작은 구멍 메우기 |
| **오프닝 (Opening)** | 이로전 + 딜레이션 | 이로전으로 노이즈를 제거한 뒤, 딜레이션으로 원래 물체 모양을 복구 | **작고 밝은 노이즈(먼지) 제거** |
| **클로징 (Closing)** | 딜레이션 + 이로전 | 딜레이션으로 구멍을 채운 뒤, 이로전으로 원래 물체 모양을 복구 | **물체 내부의 작은 구멍이나 끊어진 부분 메우기** |

### 2. 특징 추출 (Feature Extraction)

이미지에서 물체를 식별하는 데 도움이 되는 중요한 부분들을 찾아내는 작업

**엣지 검출**: 이미지에서 밝기 변화가 급격하게 일어나는 부분을 찾아서 물체의 **윤곽선**을 찾음
**코너 검출**: 선이 만나는 모서리 같은 특징적인 점들을 찾음

컨투어 **검출:**엣지 검출을 통해 찾아낸 점들 중에서 **물체의 외곽을 이루는 연속적인 선**만 연결해 하나의 닫힌 곡선으로 만든다. 그래서 물체의 모양을 파악하는 데 훨씬 유용
**키포인트 서술자**: 찾은 특징점을 숫자들의 조합으로 표현해 컴퓨터가 알아보게 만드는 기술

### **주요 특징 추출 기술 비교**

| 기술 (Technique) | 특징 (Feature) | 주요 용도 (Main Purpose) | 예시 알고리즘 (Example Algorithm) |
| --- | --- | --- | --- |
| **엣지 검출** | 이미지의 **선, 윤곽선** | 물체의 경계선 찾기, 윤곽 분석 | 캐니(Canny), 소벨(Sobel) |
| **코너 검출** | **선이 만나는 점(모서리)** | 이미지 정합, 물체 위치 파악 | 해리스(Harris), FAST |
| **컨투어 검출** | **연속적인 곡선 또는 경계** | 물체 모양 분석, 정확한 외곽선 추출 | OpenCV의 findContours 함수 |
| **키포인트 서술자** | **이미지에서 특징적인 점** | 여러 이미지에서 같은 물체 찾기, 매칭 | SIFT, SURF |

엣지 검출의 종류

| 기술 | 종류 | 특징 |
| --- | --- | --- |
| **소벨(Sobel)** | 1차 미분 | 빠른 속도와 가벼운 연산이 핵심. 그 외엔 캐니를 씀 |
| **라플라시안(Laplacian)** | 2차 미분 | 노이즈에 매우 민감해서 잘 사용되지 않음. |
| **캐니(Canny)** | 복합적 | 노이즈를 제거하고 정확한 엣지선을 찾아내는 표준 기술 단점으로는 실행시간이 느리고 구현이 복잡함 |

### **캐니 엣지 검출의 4단계**

1. **1단계) 노이즈 제거**:
**가우시안 블러**를 사용해 이미지를 부드럽게 만들어 노이즈를 없애는 단계
2. **2단계) 높은 미분값 찾기**:
이미지에서 밝기 변화가 가장 급격한 곳을 찾아 엣지가 될 후보들을 찾는 단계
3. **3단계) 최대값이 아닌 픽셀 값 0으로 치환(비최대값 억제)**:
**엣지 선을 얇고 선명하게** 만드는 단계. 엣지 후보 픽셀들 중 가장 높은 값을 가진 픽셀만 남기고 나머지는 모두 지워서 엣지 선을 **얇고 선명하게** 만든다.
4. **4단계) 하이퍼파라미터 조정을 통한 세밀한 엣지 검출(히스테리시스 임계값 적용하는 과정)**
두 개의 임계값(높은 임계값, 낮은 임계값)을 사용해서 진짜 엣지들을 연결하고, 노이즈로 인한 약한 엣지들을 최종적으로 제거해서 깨끗한 결과물을 얻음

### 3. 물체 인식 및 추적

추출한 특징들을 이용해서 이미지를 분석하는 단계

**물체 인식**: 이미지에서 특정 물체가 어디에 있는지 찾거나, 물체가 무엇인지 분류

             추출한 특징들을 가지고 미리 학습된 데이터와 비교해서 일치하는 물체를 찾아내
**물체 추적**: 동영상에서 특정 물체가 움직이는 것을 따라가는 기술
             한 프레임에서 찾은 특징점을 다음 프레임에서도 계속 찾아내면서 물체의 위치를 추적

고전 컴퓨터 비전은 이런 단계를 거쳐서 이미지를 분석

요즘은 딥러닝을 활용한 방법이 많이 쓰

컴퓨터가 직접 특징을 학습하기 때문에 훨씬 더 복잡하고 강력

---

- cv2 명령어 모음
    
    ### `cv2`에서 자주 쓰는 기능 총정리
    
    | 함수/기능 | 설명 | 용도 |
    | --- | --- | --- |
    | `cv2.imread()` | 이미지 파일 읽기 | `cv2.imread('파일이름.jpg')` |
    | `cv2.imshow()` | 창에 이미지 보여주기 | `cv2.imshow('창제목', 이미지)` |
    | `cv2.imwrite()` | 이미지를 파일로 저장 | `cv2.imwrite('저장할이름.png', 이미지)` |
    | `cv2.cvtColor()` | 이미지 색상 변환 | `cv2.cvtColor(이미지, 변환규칙)` |
    | `cv2.resize()` | 이미지 크기 변경 | `cv2.resize(이미지, (가로, 세로))` |
    | `cv2.imread()` | 이미지 파일 읽기 | `cv2.imread('파일이름.jpg')` |
    | `cv2.imread()` | 이미지 파일 읽기 | `cv2.imread('파일이름.jpg')` |
    | `cv2.imread()` | 이미지 파일 읽기 | `cv2.imread('파일이름.jpg')` |

---

## **시각적 특징(Visual Feature)**

컴퓨터가 이미지를 보고 **대상을 인식하거나 구분하는 데 사용되는 정보**

### 백본(Backbone)

딥러닝 모델, 특히 컴퓨터 비전 분야에서 **가장 핵심적인 부분**. 

이미지에서 중요한 **특징을 추출하는 역할**

**특징을 추출하기 위해 데이터를 계속 변환하는 과정**이 바로 백본의 핵심 역할

### **백본의 역할**

- **특징 추출기**: 백본은 원본 이미지 데이터를 받아서, 다음 단계의 모델이 이해하고 사용할 수 있도록 **압축된 시각적 특징을 만들어냄.**
- **사전 훈련된 네트워크**: 백본으로 사용되는 네트워크(ResNet, VGG 등)는 보통 **ImageNet** 같은 대규모 이미지 데이터셋으로 미리 학습되어 있다. 덕분에 개발자는 모델을 처음부터 학습시킬 필요 없이, 이미지를 인식하는 능력을 갖춘 백본을 바로 가져다 쓸 수 있음.
- **성능의 기초**: 백본은 모델의 **정확도, 크기, 속도**를 결정하는 중요한 요소임. 어떤 백본을 선택하느냐에 따라 최종 모델의 성능이 크게 달라질 수 있다.

### **백본의 구조**

여러 개의 레이어로 이루어져 있고 각 레이어는 이미지를 분석해 특정 수준의 특징을 찾아내는 역할을 함.

| 단계 | 특징 수준 | 추출하는 특징 | 의미 및 역할 | 예시 |
| --- | --- | --- | --- | --- |
| **1단계** | **저수준 특징** | 이미지의 가장 기본적인 요소들을 추출 | 물체의 윤곽을 파악하는 기초 단계 | 점, 선, 엣지, 단순한 모양 |
| **2단계** | **중간 수준 특징** | 저수준 특징을 조합해 더 복잡한 형태를 추출 | 기본적인 부분을 연결해 물체의 일부를 인식 | 눈, 코, 입, 바퀴, 창문 등 |
| **3단계** | **고수준 특징** | 중간 수준 특징을 종합해 가장 추상적인 대상을 인식 | 모든 정보를 모아 최종적으로 객체를 판별 | 사람 얼굴, 동물, 자동차 등 |

---

## Encoder

**Backbone**이 뽑아낸 특징들을 받아서 더 복잡하고 의미 있는 정보로 바꿔주는 단계

- **정보 압축**: 백본이 단순히 이미지의 특징들을 나열했다면, 인코더는 이 특징들을 압축하고 추상화해서 효율적인 형태로 만든다.
- **관계성 파악**: 중요한 건 단순히 정보를 모으는 게 아니라, 그 정보들 사이의 **연관성**을 학습한다는 것.

        예) 갈매기의 부리, 날개 특징이 각각 따로  아닌 같은 갈매기라는 물체에 속한다는 것을 인코더가 파악

인코더는 백본이 준비한 재료들을 가지고 **요리에 쓸 양념**을 만드는 과정

이 과정을 거쳐야만, 디코더가 최종 결과물을 더 정확하게 생성

---

## Decoder

압축된 정보를 번역해서 우리 눈에 보이도록 **최종 결과물**을 만드는 역할

- **분류(Classification)**: 그냥 "이건 차야!" 하고 딱 한마디로 말해주는 것.
- **탐지(Detection)**: "노란 차는 여기 있고, 빨간 차는 저기 있어" 하고 위치까지 알려주는 것.
- **분할(Segmentation)**: "노란 차는 이만큼의 픽셀로 이루어져 있어" 하고 정확한 모양을 그려주는 것.

**Backbone**이 무엇인지를 파악하면, **Decoder**는 그무엇을 가지고 **어떻게 보여줄지** 결정

### **디코더의 구체적인 단계**

디코더는 특징을 해석해서 최종 결과물로 변환하는 공장 이라고 생각하면 쉽다. 

이 공장 안에는 여러 가지 기계(계층, Layer)들이 있고, 어떤 제품을 만드느냐(Task)에 따라 쓰는 기계가 다름

주요 기계들

1. **완전 연결 계층 (Fully Connected Layer):** 백본이 넘겨준 특징들을 모두 연결해서 각 정답 후보의 최종 점수를 계산하는 역할. 분류 문제에서 거의 필수적으로 사용
2. **활성화 함수 (Activation Function - Softmax, Sigmoid):** 완전 연결 계층이 계산한 점수를 확률처럼 이해하기 쉬운 숫자로 바꿔주는 역할. 예) Softmax는 모든 후보의 확률을 다 더하면 1이 되도록 만들어 줘서, 모델이 얼마나 확신하는지 알 수 있게 함.
3. **업샘플링 계층 (Upsampling Layer):** 작게 압축된 특징 맵(Feature Map)의 크기를 다시 키워서 원본 이미지 크기로 복원하는 역할. 이미지를 생성하거나 분할할 때 사용
    - **전치 합성곱 (Transposed Convolution):** 가장 대표적인 업샘플링 방법. 학습을 통해 최적의 방법으로 이미지 크기를 키움.
    - **업샘플링 (Upsample) + 합성곱 (Convolution):** 이미지 크기를 단순한 방식으로 키운 다음, 합성곱 연산으로 세부 내용을 다듬는 방식
4. **어텐션 메커니즘 (Attention Mechanism):** 번역이나 요약 같은 작업에서, 결과물의 특정 부분을 만들 때 입력값의 어느 부분에 더 집중해야 할지 알려주는 똑똑한 장치. 요즘 가장 핫한 기술 중 하나

### **Task별 디코더 구성 요소**

어떤 작업을 하느냐에 따라 사용되는 디코더의 구성 요소들을 정리

| Task | 주요 구성 요소 | 역할 설명 | 가장 많이 쓰이는 조합 |
| --- | --- | --- | --- |
| **이미지 분류** | Fully Connected Layer            Softmax / Sigmoid | 특징을 종합해 클래스별 점수를 계산하고, 최종 확률로 변환. | **FC Layer + Softmax** |
| **이미지 분할** | Transposed Convolution Upsampling + Convolution | 압축된 특징 맵을 원본 이미지 크기로 확대하여 픽셀별로 분류. | **U-Net 구조의 디코더** |
| **이미지 생성** | Transposed Convolution Upsampling + Convolution | 무작위 벡터(잠재 공간)로부터 새로운 이미지를 점진적으로 생성. | **GAN의 생성자(Generator)** |
| **자연어 처리** | RNN (LSTM, GRU)            Attention Mechanism | 문장의 맥락을 이해하고 다음 단어를 예측하거나 번역 결과를 생성. | **Transformer Decoder** |
- 가장 기본적이고 많이 쓰이는 디코더는 **분류 작업의 Fully Connected Layer + Softmax 조합**
- 하지만 이미지 분할이나 생성 분야에서는 **U-Net 구조처럼 업샘플링 계층을 사용하는 디코더**가 표준
- 최근 자연어 처리 분야에서는 **어텐션 메커니즘을 기반으로 한 트랜스포머 디코더**가 압도적으로 많이 사용
