## 1. 딥러닝 기초 개념

### 1.1 딥러닝이란

- 인공신경망을 기반으로 한 머신러닝의 한 분야
- 다층 신경망 구조를 통해 복잡한 패턴을 학습
- 인간의 뇌 신경망을 모방한 계산 모델

### 1.2 머신러닝 vs 딥러닝

- 머신러닝: 특징 추출을 수동으로 수행
- 딥러닝: 특징 추출을 자동으로 학습
- 데이터량이 많을수록 딥러닝이 우수한 성능

### 1.3 핵심 용어

- 뉴런(Neuron): 신경망의 가장 작은 계산 단위
- 가중치(Weight): **입력 신호의 중요성을 결정**하는 값 뉴런이 신호 받을때 뭐가 중요한지 숫자로 나타낸 것
- 편향(Bias): 뉴런이 신호를 내보낼지 말지 결정하는 **임계점**을 조정
- 순전파(Forward Propagation): 데이터가 신경망을 통과하는 과정. 입력에서 출력으로 계산
- 역전파(Backpropagation): 오차를 줄이기 위해 거꾸로 돌아가는 과정
- 순전파를 통해 나온 예측값이 실제 정답과 얼마나 다른지(오차)를 계산하고, 그 오차를 다시 거꾸로 되돌려 보내면서 가중치와 편향을 업데이트하는 과정

---

## 2. 신경망 구조

신경망 모델을 어떻게 쌓을지에 대한 설계도. 층(Layer)의 깊이와 뉴런의 연결 방식에 따라 모델의 학습 능력이 달라진다.

### 2.1 퍼셉트론

- 하나의 뉴런으로 이루어진 가장 단순한 신경망 모델
- 선형 분리 가능한 문제만 해결
- 수식: y = f(wx + b)

### 2.2 다층 퍼셉트론(MLP)

- 입력층, 은닉층, 출력층으로 구성
- 비선형 활성화 함수 사용
- XOR 문제와 같은 비선형 문제 해결 가능

### 2.3 심층 신경망

- 3개 이상의 은닉층을 가진 네트워크
- 계층적 특징 학습
- 표현 학습 능력 향상

---

## 3. 활성화 함수

뉴런의 계산 결과에 비선형성을 추가해 모델이 복잡한 문제를 풀 수 있게 돕는 역할.

### 3.1 시그모이드(Sigmoid)

S자 모양의 곡선을 가진 함수. 모든 입력값을 0과 1 사이의 값으로 바꿔줌

- 함수: σ(x) = 1/(1+e^(-x))
- 출력 범위: (0, 1)
- 단점: 기울기 소실 문제
- 이진 분류의 출력층에서 최종 확률을 나타낼 때 거의 유일하게 쓰임(은닉층은 ReLU)

### 3.2 하이퍼볼릭 탄젠트(tanh)

**시그모이드 확장판. 모든 입력값을 -1부터 1까지**의 값을 출력

- 함수: tanh(x) = (e^x - e^(-x))/(e^x + e^(-x))
- 출력 범위: (-1, 1)
- 시그모이드보다 기울기 소실 문제 완화
- 예전에는 순환 신경망(RNN)에서 사용됐지만, 요즘은 ReLU나 그 외 다른 활성화 함수들이 더 좋은 성능을 보여주기 때문에 **거의 사용되지 않는 추세. LSTM 이나 GRU 주로사용 활성화함수도 ReLU계열 씀**

### 3.3 ReLU (Rectified Linear Unit)

**입력값이 0보다 크면 그 값을 그대로 출력**하고, **0보다 작거나 같으면 무조건 0을 출력**

- 함수: f(x) = max(0, x)
- 수식이 매우 단순해 학습 효율 훨씬 빠름.
- 기울기 소실 문제 해결, 은닉층에서 주로 사용
- 단점: 뉴런으로 들어오는 입력값이 모두 음수라면, 그 뉴런은 항상 0만 출력

                 가중치 업데이트가 멈춰서 해당 뉴런이 학습을 하지 못하는 죽은 상태가 됨

### 3.4 기타 활성화 함수 (거의 은닉층)

- Leaky ReLU:  ReLU는 입력값이 0보다 작으면 출력이 0이 돼서 뉴런이 '죽는' 문제가 있었지. Leaky ReLU는 이 문제를 해결하기 위해 0보다 작은 값에도 아주 작은 기울기(0.01)를 줘. 덕분에 뉴런이 죽지 않고 학습을 이어갈 수 있음
- ELU: 출력값의 평균이 0에 가깝게 맞춰져서 학습 속도가 빨라지는 효과가 있음.ReLU보다 학습이 안정적
- Swish: 시그모이드 함수가 결합된 형태. ReLU보다 부드러운 곡선 형태를 띠어서 깊은 신경망에서 더 좋은 성능을 낼 수 있다고 알려져 있음
- GELU: 현재 **트랜스포머** 기반 최신 모델(GPT)에서 가장 많이 쓰이는 활성화 함수. 입력값에 확률적인 성질을 적용해서 학습 효율을 높임
- 소프트맥스 : 다중 분류의 출력층에서만 주로 쓰임. 여러 클래스의 확률을 나타낼 때 사용

### 3.5 선형 활성화

- 활성화 함수 없이, 입력값에 가중치를 곱하고 편향을 더한 값을 **그대로 출력**하는 방식
- 딥러닝 초보자들이 활성화 함수를 배울 때 잘 언급되지 않는 이유, **은닉층에서는 거의 사용하지 않기 때문**
- 선형 활성화 함수를 쓰면 아무리 층을 많이 쌓아도 결국 **하나의 직선**과 같아져서 복잡한 문제를 해결할 수 없다.
- **회귀 문제**의 **출력층에서 주로 쓰임. (숫자의 범위가 정해져 있지 않은 경우)**
- 정해져있으면 거의 시그모이드 사용 (회귀 문제에서 출력값 0과1)

---

## 4. 손실 함수

모델의 예측값이 정답과 얼마나 다른지 측정하는 역할

### 4.1 회귀 문제

- 평균 제곱 오차(MSE): 정답과 예측값의 **차이를 제곱**해서 평균 낸 값. 오차가 클수록 손실값이 늘어남
- 평균 절대 오차(MAE): 정답과 예측값의 **차이에 절댓값**을 씌운 뒤 평균 낸 값. 이상치 많을때 쓰기 좋음
- Huber Loss: MSE와 MAE의 결합. 오차가 작을 때는 MSE처럼, 오차가 클 때는 MAE처럼 선형적으로 변함

### 4.2 분류 문제

- 이진 교차 엔트로피: 이진분류할때 씀. 정답이 1일 때 예측 확률이 1에 , 정답이 0일 때 예측 확률이 0에 가까워지게 유도
- 범주형 교차 엔트로피: 다중분류에 사용. 정답 클래스에 해당하는 예측 확률(pi)을 높이도록 유도
- Sparse Categorical Crossentropy: 정답 레이블을 숫자로 입력. 원-핫 인코딩 생략하고 싶을때 사용

### 4.3 기타 손실 함수

- Focal Loss: 불균형 데이터용
- Dice Loss: 의료 영상처럼 픽셀 단위로 분류하는 문제(세그멘테이션)에 사용
- Triplet Loss: 비슷한 데이터끼리는 가깝게, 다른 데이터끼리는 멀게 만드는 임베딩 학습에 사용

### **주요 손실 함수 종류별 비교**

|  손실 함수 종류 |       문제 유형 |                           특징 |            대표적인 손실 함수 |
| --- | --- | --- | --- |
| **회귀 문제용** | **연속된 숫자 예측** | 정답과 예측값의 **수치적 차이**를 줄이는 데 초점을 맞춰. 오차를 제곱하거나 절댓값을 취해서 계산하지. | **평균 제곱 오차(MSE)**, **평균 절대 오차(MAE)**, Huber Loss |
| **분류 문제용** | **범주(클래스) 예측** | 정답 클래스의 **확률을 높이는** 방향으로 학습해. 예측 확률 분포와 정답 분포의 차이를 줄여. | **이진 교차 엔트로피**, **범주형 교차 엔트로피**, Sparse Categorical Cross-entropy |
| **기타 손실 함수** | **특수 목적** | 특정 상황(데이터 불균형, 이미지 분할 등)에서 일반적인 손실 함수보다 더 좋은 성능을 내기 위해 만들어졌어. | **Focal Loss**, Dice Loss, Triplet Loss |

250811

---

## 5. 최적화 알고리즘

모델의 손실값을 최소화하기 위해 **가중치와 편향을 업데이트하는 방법**

### 5.1 경사 하강법(Gradient Descent)

손실 함수 그래프의 가장 낮은 지점(최저점)을 찾아가는 방법

- 배치 경사 하강법: 모든 데이터 사용해 기울기 계산. 정확하지만 데이터 많으면 느림
- 확률적 경사 하강법(SGD): 데이터를 **하나씩** 뽑아 기울기를 계산. 속도 빠름, 기울기가 불안정하게 변동
- 미니배치 경사 하강법: 배치와 SGD의 절충. 데이터 나눠서 업데이트. 가장 많이 쓰는 방법

대부분 딥러닝 모델은 데이터가 많고 안정적인 학습이 중요해서 미니배치 경사 하강법 많이 쓴다.

### 5.2 모멘텀 기반 방법

경사 하강법의 단점을 보완하기 위해 **'관성(Momentum)'** 개념을 추가한 방법

- Momentum: 이전 기울기 정보 기억. 현재 기울기와 합쳐서 다음 방향을 결정
- Nesterov Accelerated Gradient(NAG): 관성으로 이동할 예상위치 기울기 미리 계산

### 5.3 적응적 학습률 방법

가중치를 얼마나 크게 업데이트할지 정하는 값. 
학습률을 모든 매개변수에 똑같이 적용하지 않고, **매개변수마다 다르게 조절**

- AdaGrad: 자주 변하지 않는 매개변수는 크게 업데이트하고, 자주 변하는 매개변수는 작게 업데이트
- RMSProp: AdaGrad의 학습률 빠른 문제 개선. 최근 기울기 정보만 반영해 효율적인 학습률 조절
- Adam: RMSProp + Momentum 빠른 학습 속도. 안정적인 학습
- AdamW: 가중치 감쇠 개선. 과적합이 우려될 때 사
- RAdam: Adam의 예열 개선

최근에는 **Adam**을 기본으로 사용하고, 특정 문제에 따라 다른 알고리즘을 시도

---

## 6. 정규화 기법

모델이 학습 데이터에만 너무 맞춰지는 과적합을 막고, 학습을 더 안정적으로 만들기 위한 기술

### 6.1 가중치 정규화

모델의 가중치에 벌칙을 줘서 가중치가 너무 커지는 걸 막는 방법. 

가중치가 너무 크면 모델이 특정 데이터에만 과도하게 민감해짐

- L1 정규화: 가중치의 **절댓값**에 비례하는 벌칙 줌. 중요하지 않은 가중치 0으로 만들어 **모델 단순화**
- L2 정규화: 가중치의 **제곱**에 비례하는 벌칙 줌. 가중치를 0에 가깝게 만들지만, 완전히 0으로 만들진 않음
- Elastic Net: L1 + L2 결합 = 가중치0으로 만들어 단순하면서도 과적합을 막는데 효과적

### 6.2 드롭아웃(Dropout)

훈련 중 일부 뉴런을 무작위로 제거해서 학습시키는 방법

- 과적합 방지 효과 : 매번 다른 뉴런 조합으로 학습. 특정 뉴런이 학습에 독점적 기여하는것을 막
- 앙상블 효과 : 마치 여러 개의 작은 모델을 학습시키는 것과 같은 효과

### 6.3 배치 정규화(Batch Normalization)

데이터가 각 층을 통과할 때마다 **평균을 0, 분산을 1**로 맞춰서 정규화하는 방법

- 내부 공변량 이동 감소 : 층을 거칠 때마다 데이터 분포가 바뀌는 현상을 줄여줌(학습 불안정 원인)
- 학습 안정성 향상 : 더 빠르고 안정적으로 진행

### 6.4 기타 정규화

- Layer Normalization: 층별 정규화 (배치 크기 작을때 유용)
- Group Normalization: 그룹별 정규화 (채널을 여러 그룹으로 나눠 정규화)
- Instance Normalization: 인스턴스별 정규화 (데이터 샘플 하나하나 정규화함)

경망의 학습 흐름 전체를 고려한 가장 올바른 순서

`레이어(Layer) -> 배치 정규화(Batch Normalization)` 

`-> 활성화 함수(Activation) -> 드롭아웃(Dropout)`

---

## 7. 합성곱 신경망(CNN)

**이미지 데이터**를 처리하는 데 특화된 딥러닝 모델. 

인간의 시각 시스템을 모방해 더 효율적으로 분석

### 7.1 기본 구조

- 합성곱 층(Convolution Layer) : 이미지의 특징 추출
- 풀링 층(Pooling Layer) : 합성곱에서 추출한 특징 압축.

                                                  이미지 크기 줄여 계산량 감소 및 주요 특징만 남겨 과적합 방지

- 완전 연결 층(Fully Connected Layer) : 압축된 특징으로 이미지 분류 (일반적인 신경망과 같은구조임)

### 7.2 합성곱 연산

이미지를 필터로 스캔하며 특징을 추출하는 과정

- 필터(커널): 이미지의 특징을 감지하는 작은 행렬. 필터가 지나가며 특징을 찾음
- 스트라이드: 필터를 한 칸 or 몇 칸씩 이동할지 정하는 간격. 스트라이드 크면 출력이미지 크기는 작아짐
- 패딩: 필터가 이미지 경계를 벗어나지 못하게 이미지 외곽에 0을 채우는 작업
- 채널: 컬러 이미지의 경우 RGB(빨강, 초록, 파랑) 세 가지 채널로 구성 (흑백은 채널이 하나)

### 7.3 풀링 연산

이미지의 크기를 줄이는 작업

- Max Pooling: 특정 영역에서 **가장 큰 값**만 남겨서 특징을 압축
- Average Pooling: 특정 영역의 **평균값**을 계산해서 특징을 압축
- Global Average Pooling: 모든 픽셀의 평균을 계산해서 최종 특징 벡터 생성 완전

                                                    연결 층을 대체해서 사용되기도 .

### 7.4 주요 CNN 아키텍처

- LeNet-5: 최초의 CNN모델. 손글씨 숫자를 인식하는 데 사용
- AlexNet: 2012년 이미지넷 대회에서 우승하며 딥러닝 붐 일으킴
- VGG: 작은 필터(3x3)를 여러 층 쌓아서 깊이를 늘렸고, 모델의 깊이가 성능에 중요하다는 걸 보여줌
- ResNet: 잔차 연결로 층이 매우 깊어져도 성능이 떨어지지 않게 만듦
- Inception: 다양한 크기 필터 병렬로 적용해 효율 높임
- DenseNet: 모든 층 간 연결해 정보의 흐름을 개선, 기울기 소실 문제를 완화함
- EfficientNet: 모델의 깊이, 너비, 해상도를 효율적으로 조절해서 성능을 높임

---

## 8. 순환 신경망(RNN)

**시퀀스 데이터 처리에 특화된 모델. 같은 뉴런을 반복해서 사용**해 데이터를 처리

**시퀀스 데이터:** **시간의 흐름에 따라 순서가 중요한 데이터**

### 8.1 기본 RNN

현재의 입력을 처리할 때 이전 단계의 정보(은닉 상태)를 함께 사용

- 시퀀스 데이터 처리 : 데이터를 한 단계씩 순차적으로 처리 후 결과를 은닉상태에 저장
- 예측: 이 은닉 상태라는 메모리를 다음 단계 입력과 함께 사용해 더 정확한 예측을 함
- 기울기 소실/폭발 문제 있음
- **기울기 소실**: 오래된 정보의 중요도가 점차 사라지는 현상.
- **기울기 폭발**: 학습 과정에서 가중치가 너무 크게 증가해 불안정해지는 현상.

### 8.2 LSTM (Long Short-Term Memory)

- 기울기 소실 문제 해결 위해 나옴
- 셀 상태 라는 별도의 메모리 공간을 둬서 중요 정보 장기 기억
- 게이트 메커니즘: 망각, 입력, 출력 3개 게이트를 통해 어떤 정보를 기억,폐기할지 스스로 판단

### 8.3 GRU (Gated Recurrent Unit)

- LSTM의 복잡한 구조 간소화 버전
- 재설정, 업데이트 2개의 게이트만 사용해 LSTM과 비슷한 성능 + 효율적
- 셀 상태와 은닉 상태를 통합. 망각 게이트와 입력 게이트를 하나의 업데이트 게이트로 합침

### 8.4 양방향 RNN

데이터를 **정방향**뿐 아니라 **역방향**으로도 처리해서 문맥을 더 정확하게 파악

- 정방향 역방향 정보 모두 써서 의미 더 정확히 파악
- 모든 데이터가 다 들어와야 다음 단어를 예측할 수 있어서 실시간 데이터 처리는 어려움

기본 RNN은 **기울기 소실/폭발 문제** 때문에 거의 안씀

**일반적인 상황**에서는 계산이 더 빠르고 효율적 GRU먼저 사용

**복잡하고 긴 시퀀스 데이터** 처리할 때, or GRU가 성능이 안 나올 땐 LSTM 사용

양방향 RNN은 **실시간 예측이 필요 없는 상황**에서 문맥 정보가 중요한 문제에 주로 사용
예시) 자연어 처리, 음성 인식, 기계 번역

---

## 9. 트랜스포머(Transformer)

RNN의 한계인 순차적 데이터 처리 문제를 해결한 모델

RNN처럼 순서대로 데이터를 처리하지 않고, 

문장 전체를 한 번에 처리하는 **어텐션 메커니즘**을 기반으로 만든 모델이다.

현재 자연어 처리, 컴퓨터비전, 음성처리, 시계열데이터에 중요하게 쓰임

### 9.1 어텐션 메커니즘

모델이 문장을 처리할 때, 중요한 단어에 더 **집중**하도록 돕는 기술

- 가중치를 통해 중요한 정보에 집중
- 병렬 처리 가능 : 모든 단어 간의 관계를 한번에 계산할 수 있어서 학습 속도 매우 빠름

### 9.2 셀프 어텐션

어텐션 메커니즘의 한 종류로, 문장 **내부의 단어들 간 관계**를 파악하는 기술

- 입력 시퀀스 내부 관계 모델링
- 쿼리, 키, 값 3가지 벡터를 이용해 문장의 각 단어에 대한 중요도를 계산(쿼리와 키 비교해 중요도 계산)

             쿼리: "내가 어떤 단어를 찾고 있지?" 라는 질문

             키: "나는 어떤 단어야? " 라는 정체성

             값: "나의 정보는 이거야" 라는 실제 정보

- 다중 헤드 어텐션 :여러 개의 셀프 어텐션 메커니즘을 동시에 사용. 다양한 관계 한번에 파악하는 기술

### 9.3 트랜스포머 구조

- 인코더-디코더 구조로 이루어짐

          **인코더**: 입력 문장을 읽고 이해해서 문맥 정보를 벡터로 만드는 역할

          **디코더**: 인코더가 만든 벡터를 바탕으로 출력 문장을 생성하는 역할

- 위치 인코딩 : 트랜스포머는 문장 순서대로 처리하지 않으니 위치정보 필요. 위치인코딩이 그 역할 담당
- 층 정규화 : 각 층 출력을 정규화해 학습 안정적으로 만듦
- 피드포워드 네트워크 : 인코더 디코더 안에 작은 신경망. 문맥 정보를 복잡하게 변환함

### 9.4 트랜스포머 기반 모델

- BERT(버트): 양방향 인코더. **인코더**만 사용하고 문장 앞뒤 문맥 모두 고려해 깊이 있게 이해
- GPT: 생성형 디코더. **디코더**만 사용. 이전 단어 보고 다음 단어 예측 텍스트생성에 특화
- T5: 인코더+디코더 모든 자연어 처리 문제를 '텍스트에서 텍스트로 변환'하는 형식으로 해결하는 모델
- Vision Transformer: 이미지용 트랜스포머. 이미지를 작은 조각으로 나눈 뒤, 그 조각들의 관계를 파악해서 이미지를 이해

---

## 10. 생성 모델

학습 데이터와 비슷한 새로운 데이터를 만드는 딥러닝 모델

### 10.1 오토인코더(Autoencoder)

입력 데이터를 압축(인코딩)했다가 다시 복원(디코딩)하는 방식으로 학습

- 입력 데이터를 잠재 공간이라는 작은 차원으로 압축하는 **인코더**와,

        압축된 데이터 원래대로 복원하는 **디코더**로 구성

- 변분 오토인코더(VAE): 오토인코더의 한 종류, 잠재 공간을 **확률 분포**로 만듦. 새로운 데이터 무작위 생성

### 10.2 생성적 적대 신경망(GAN)

생성자와 판별자라는 두 개의 신경망이 서로 경쟁하며 학습하는 모델

- **생성자**: 진짜와 비슷한 가짜 데이터를 만듦
- **판별자**: 생성자가 만든 가짜 데이터와 진짜 데이터를 구분하는 역할
- 민맥스 게임 이론 : 생성자는 판별자를 속이고, 판별자는 생성자를 이기려하는 제로섬 게임을 통해 둘 다 성능이 향상
- 다양한 GAN 변형

         **DCGAN** : CNN을 GAN에 적용해 이미지 생성 품질을 크게 높임. 

                          GAN의 기본 모델로, 이미지 생성 원리를 이해하는 데 중요.

         **WGAN** : GAN의 학습이 불안정하다는 큰 문제점을 해결한 모델. 

                        GAN을 실제로 적용하려면 WGAN의 원리를 알아야 안정적으로 학습시킬 수 있다.

    **StyleGAN** : 현실과 구별하기 힘든 고해상도 이미지를 만들어내는 기술의 정점. 

                          이미지 생성 분야의 최신 동향을 파악하는 데 필수적.

### 10.3 확산 모델(Diffusion Model)

**데이터에 노이즈를 추가했다가 다시 제거하는 과정**을 반복해서 데이터를 생성

- 노이즈 추가 및 제거 과정하는 방식으로 학습
- 고품질 이미지 생성 : 이 과정을 통해 매우 사실적이고 고품질의 이미지 생성
- 확산 모델의 대표적인 변형

        DDPM: 노이즈 제거 과정에 **마르코프 연쇄**를 사용해 이미지를 생성
        DDIM: 이 과정을 좀 더 효율적으로 바꿔서 훨씬 빠르게 이미지를 생성할 수 있도록 개선

마르코프 연쇄 (Markov Chain)
어떤 상태가 다음 상태로 바뀔 때, **바로 직전의 상태에만 의존**하는 확률 모델
과거의 모든 상태를 기억하는 게 아니라, 현재 상태만으로 미래를 예측

### 10.4 플로우 기반 모델

**가역 변환**을 이용해 데이터를 생성하는 모델

- **가역 변환**: 변환을 거꾸로 되돌릴 수 있다는 뜻 덕분에 데이터 확률 정확하게 계산할 수 있다.
- 정확한 확률 계산 : 모델이 생성한 데이터가 얼마나 확률적으로 높은지 정확히 알 수 있어서, 데이터 압축이나 이상 탐지 같은 분야에 활용
- Normalizing Flow(정규화 플로우) : 플로우 기반 모델 중 가장 대표적인 모델

        복잡한 데이터분포를 단순한 정규분포로 변환하는데 특화

        

        

---

## 11. 강화학습과 딥러닝

### 11.1 심층 강화학습

강화학습은 에이전트가 환경과 상호작용하며 보상을 최대화하는 방법을 스스로 배우는 것. 

이 강화학습에 **딥러닝**을 결합한 것이 심층 강화학습

- DQN: 딥러닝 + Q-learning

        Q-learning은 에이전트가 어떤 행동을 해야 가장 좋은 보상을 얻을 수 있는지 계산하는 방법

        DQN은 이 계산을 딥러닝 모델로 처리해서 복잡한 환경에서도 학습할 수 있게 됨

- 정책 경사법: 에이전트가 어떤 행동을 할 확률(정책)을 직접 학습하는 방법

                              예) REINFORCE : 가장 기본적인 정책 경사법 알고리즘

                                    A3C : REINFORCE의 단점 보완. 에이전트를 동시에 학습시켜 학습속도 높임

- Actor-Critic(크리틱) 방법 : 정책 경사법+Q-learning 임.

                                             **Actor**는 행동을 결정, **Critic**은 그 행동을 평가

### 11.2 주요 알고리즘

DQN이나 Actor-Critic 같은 기본 방법론에서 발전한 주요 알고리즘들

- PPO: **정책 경사법**의 한 종류로, 학습이 불안정하다는 단점을 개선한 알고리즘
- DDPG: **Actor-Critic 방법**을 연속적인 행동 공간에 적용. 무수히 많은 경우의 수 있을때 사용
- SAC(소프트 액터-크리틱): **DDPG**를 개선한 알고리즘으로, 탐험을 통해 더 다양한 전략을 배우도록 만듦
- Rainbow DQN: DQN 개선 통합한 알고리즘. 학습 속도를 높이고 성능 향상시킴

---

## 12. 실무 적용

### 12.1 데이터 전처리

- 데이터 정규화/표준화 : 데이터의 범위를 일정하게 맞춰서 모델이 안정적으로 학습하게 도움
- 결측치 처리
- 이상치 탐지 및 제거
- 데이터 증강 : 이미지를 회전시키거나 뒤집어서 **데이터의 양을 늘려주는** 기술 (과적합도 막아줌)

### 12.2 모델 선택

- 문제 유형별 적합한 아키텍처 : 이미지 분류는 CNN, 시퀀스 데이터는 RNN/트랜스포머 같은 모델 선택
- 하이퍼파라미터 튜닝 : 학습률, 배치 크기 같은 모델의 성능에 영향을 주는 **설정값**을 조정
- 교차 검증 : 데이터를 여러 묶음으로 나눠서 모델을 평가하는 방법
- 앙상블 방법 : 여러 모델을 학습시킨 뒤 결과를 종합해서 더 좋은 성능을 내는 방법

### 12.3 성능 평가

- **분류 지표**:
    - **정확도(Accuracy)**: 전체 데이터 중 정답을 맞힌 비율.
    - **정밀도(Precision)**: 모델이 '정답'이라고 예측한 것 중 진짜 정답의 비율.
    - **재현율(Recall)**: 실제 정답 중 모델이 정답이라고 맞힌 비율.
    - **F1 점수**: 정밀도와 재현율의 균형을 나타내는 값.
- **회귀 지표**:
    - **MSE(평균 제곱 오차)**: 예측값과 실제값의 차이를 제곱해서 평균 낸 값.
    - **MAE(평균 절대 오차)**: 예측값과 실제값의 절댓값 차이를 평균 낸 값.
    - **R²(결정계수)**: 모델이 얼마나 데이터를 잘 설명하는지 나타내는 지표.

- 혼동 행렬 : 모델의 예측 결과를 표로 정리해서 어떤 오류가 많은지 한눈에 보여
- ROC 곡선, AUC : 분류 모델의 성능을 시각적으로 평가하는 지표.

### 12.4 모델 해석

- LIME: 예측 결과를 **지역적으로** 설명해주는 방법
- SHAP: 게임 이론을 바탕으로 각 특징이 예측에 얼마나 영향을 줬는지 설명
- Grad-CAM: CNN 모델이 이미지의 어느 부분에 집중해서 예측했는지 **시각적으로** 보여줌
- 어텐션 가중치 분석 : 트랜스포머 모델이 어떤 단어에 집중했는지 분석

---

## 13. 최신 동향

### 13.1 대형 언어 모델(LLM)

- GPT-4, Claude, PaLM
- 프롬프트 엔지니어링 : LLM에게 우리가 원하는 답변을 얻기 위해 입력을 최적화하는 기술
- In-Context Learning: 모델이 별도 학습 없이, 프롬프트에 제공된 예시만 보고 새로운 작업을 수행하는 능력
- Chain-of-Thought: 복잡한 문제에 대해 LLM이 중간 추론 과정을 단계별로 생각하도록 유도하는 기술

### 13.2 멀티모달 학습

텍스트, 이미지, 오디오 등 여러 종류의 데이터를 함께 학습해서 이해하는 기술

- 텍스트-이미지: **CLIP**은 텍스트와 이미지의 관계 학습, **DALL-E**는 텍스트를 입력받아 이미지를 생성
- 비전-언어 모델: 이미지와 텍스트를 함께 이해해서 더 풍부한 정보를 파악
- 오디오-비전 융합: 소리와 영상 정보를 함께 분석해서 상황을 더 정확하게 이해

### 13.3 효율적인 딥러닝

모델의 크기가 커지며 학습과 추론 비용이 높아짐. 그래서 모델을 더 작고 빠르게 만드는 기술들이 중요

- 모델 압축:

        프루닝: 중요하지 않은 가중치(뉴런)를 제거해서 모델을 가볍게 만듦

        양자화: 모델의 가중치를 더 적은 비트로 표현해서 크기를 줄임

- 지식 증류: 크고 성능 좋은 모델의 지식을 작고 효율적인 모델에게 전달해 성능을 높임
- Neural Architecture Search
- Edge AI: 스마트폰이나 인터넷 연결 없이 작동하는 기기에서도 AI를 효율적으로 실행하는 기술

### 13.4 연합 학습

여러 기기가 데이터를 직접 공유하지 않고도, 각자 가진 데이터로 모델 학습 후 그 결과만 합치는 기술

- 분산 데이터에서 학습: 여러 곳에 분산된 데이터를 한곳에 모으지 않고도 모델을 학습
- 개인정보 보호: 데이터를 직접 공유하지 않으니까 개인정보 유출 위험이 크게 줄어든다.
- 통신 효율성: 모델의 업데이트 정보만 주고받기 때문에 통신 비용이 절약

---

## 14. 도구 및 프레임워크

### 14.1 주요 프레임워크

- TensorFlow: 구글 개발. 모델을 만들고 배포하는 데 필요한 기능이 모두 갖춰져 있음
- PyTorch: 페이스북 개발. 코드가 직관적이고 사용하기 쉬워서 연구 개발용으로 쓰
- Keras: 서플로우 위에서 돌아가는 고수준 API. 코드가 간단한 게 장점
- JAX: 구글이 만듦 함수형 프로그래밍. 높은 성능과 유연성을 제공해서 연구용으로 주목

### 14.2 개발 환경

- Jupyter Notebook: 대화형 개발
- Google Colab: 클라우드 환경
- Weights & Biases: 실험 관리
- MLflow: ML 생명주기 관리

### 14.3 배포 도구

- TensorFlow Serving
- ONNX: 모델 교환 표준
- TensorRT: NVIDIA 추론 최적화
- Docker: 컨테이너화

---

## 15. 윤리와 한계

### 15.1 편향성 문제

AI 모델이 학습 데이터에 특정 편견이 있을 때, 모델도 그 편견을 그대로 학습해서 차별적인 결과를 내놓음

- 데이터 편향: 학습 데이터에 특정 인종, 성별에 대한 차별적인 내용이 포함될 때 발생
- 알고리즘 편향: 알고리즘 설계 과정에서 의도치 않게 특정 그룹에 불리한 결과를 초래
- 공정성 메트릭: 모델이 특정 집단에 **차별적인 예측**을 하지 않고 **공정하게 작동하는지** 측정하는 지표

### 15.2 설명 가능성

딥러닝 모델은 결과는 잘 내지만, 왜 그런 결과를  설명하기 어려운 **블랙박스** 문제 때문에 생기는 한계

- XAI (Explainable AI): AI가 왜 그런 결정을 내렸는지 인간이 이해할 수 있도록 설명해주는 기술
- 투명성과 책임성: AI의 결정을 이해해야만 문제 발생 시 누가 책임져야 하는지, 어떤 부분을 개선해야 하는지 알 수 있음

### 15.3 개인정보 보호

AI 모델이 학습 데이터에 있는 개인정보를 기억하거나 유출할 수 있다는 문제

- 차등 프라이버시: 데이터에 의도적인 노이즈를 추가해서 개인정보를 보호하는 기술
- 연합 학습: 데이터를 공유하지 않고 학습 결과를 모아서 모델을 만드는 방법
- 동형 암호: 데이터를 암호화한 상태에서도 연산이 가능하게 해서, 암호를 풀지 않고도 데이터를 분석

### 15.4 환경 영향

대규모 딥러닝 모델의 학습 과정에서 발생하는 에너지 소비와 탄소 배출 문제

- 에너지 소비: 대형 모델을 학습시키려면 수천 대의 GPU를 수개월 동안 돌려야 해서 엄청난 전기를
- 탄소 발자국: 이 과정에서 발생하는 탄소 배출량도 엄청나서 환경에 큰 부담
- 지속 가능한 AI: 모델을 더 효율적으로 만들고, 에너지 효율이 높은 하드웨어를 사용하는 등 환경 부담을 줄이기 위해 노력

---

## 16. 학습 로드맵

### 16.1 기초 단계 (1-3개월)

1. 선형대수, 미적분, 확률통계 복습
2. Python 프로그래밍 숙달
3. NumPy, Pandas 라이브러리 학습
4. 기본 신경망 이론과 구현

### 16.2 중급 단계 (3-6개월)

1. TensorFlow/PyTorch 프레임워크 학습
2. CNN으로 이미지 분류 프로젝트
3. RNN으로 시계열/NLP 프로젝트
4. 정규화 기법과 최적화 실험

### 16.3 고급 단계 (6개월 이상)

1. 트랜스포머와 어텐션 메커니즘
2. 생성 모델 구현과 실험
3. 논문 읽기와 구현
4. 실무 프로젝트 진행

### 16.4 전문가 단계

1. 최신 연구 동향 파악
2. 새로운 아키텍처 설계
3. 오픈소스 기여
4. 연구 논문 작성
