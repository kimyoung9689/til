오늘의 할 일
날짜: 2025-09-04


모델 선택 및 하이퍼파라미터 설정

ViT 기반 모델 앙상블 후보에 추가해 실험해보기
지금까지의 EDA 분석을 종합해 볼 때, 현재 가장 큰 문제는 과적합과 특정 클래스(7번)에 대한 낮은 성능이라고 판단됨

과적합 문제: 해상도를 높여서 Valid F1 Score는 0.995까지 높였지만, Test F1 Score는 오히려 0.5190으로 크게 떨어짐
이는 모델이 훈련 데이터에 너무 맞춰져서 실제 평가 데이터에 일반화되지 못한다는 걸 의미
Valid 데이터에 적용한 더 심하게 훼손하는 변형이 robustness를 높이려는 의도였지만,
오히려 과도한 증강이 모델의 일반화 능력을 떨어뜨렸을 가능성도 배제할 수 없다.

7번 클래스 오분류: 7번 클래스(통원확인서 등)가 14번 클래스와 포맷이 비슷해서 오분류율이 높다는 문제를 파악.
해상도를 높여서 valid 점수를 올렸지만, 이게 test 점수까지 이어지지 않음

해볼 것들
핵심은 과적합을 줄이고, 모델의 일반화 성능을 높이는 것

과적합 완화 및 일반화 성능 개선

하이퍼파라미터 튜닝: 현재 학습 중인 모델들이 과적합되고 있을 가능성이 높다.
이를 해결하기 위해 Early Stopping의 patience 값을 5로 되돌리거나,
더 보수적인 값으로 조정해서 모델이 너무 오래 학습하지 않도록 시도해보기

증강 튜닝: train data의 augmentation 확률 강화가 과적합의 원인일 수 있다.
각 증강 기법의 확률을 미세하게 조정하고, valid 데이터에 심한 훼손을 적용하는 것은 TTA으로만 사용하고
학습/검증 단계에서는 제거하는 걸로 적용해보기.
Valid/Test 데이터셋에는 단순히 Resize & Normalize만 적용하는 게 더 나을 수도 있다는 생각

학습률 조정: 학습률이 너무 높으면 모델이 최적점에 도달하지 못하고 불안정하게 학습될 수 있으니,
CosineAnnealingLR 스케줄러의 설정과 함께 학습률을 더 작은 값(예: 1e-4)으로 시작하는 것도 생각해보기

모델 및 앙상블 전략 재검토
ViT 기반 모델 시도: 이전에 Focal Loss 적용 후에도 7번 클래스 오분류 문제가 남아있음.
ViT는 이미지의 전반적인 구조와 레이아웃을 파악하는 데 뛰어나서,
텍스트가 빽빽한 문서 이미지의 미묘한 차이를 더 잘 구분할 수 있다.
ViT-Large나 Swin Transformer 같은 모델 시도해보기

앙상블 전략 수정: 현재 앙상블은 단순하게 여러 모델의 예측을 합치는 방식임
Case(1, 2) 앙상블의 낮은 점수가 ConvNeXtV2-Base_608 모델의 낮은 Test 점수 때문임을 확인했으니,
과적합이 심한 모델은 앙상블에서 제외하거나 가중치를 낮춰보기

OOF 앙상블: StratifiedKFold로 학습했으니, 각 Fold의 예측 결과를 활용하는 OOF 앙상블을 적용
모델이 과적합되지 않은 상태에서 각 Fold의 검증 데이터에 대한 예측을 사용하므로, 안정적인 성능이 기대됨

코드 개선 및 재실험
Focal Loss 재적용: Focal Loss가 Fold 3의 점수를 크게 올린 효과는 확인.
과적합이 발생하지 않도록 하이퍼파라미터와 함께 신중하게 다시 실험해보기

이미지 사이즈: 해상도를 높이는 것이 Valid 점수에만 영향을 미쳤으므로, 당분간은 auto 사이즈를 기본으로 하되, 7번 클래스 예측에 특화된 모델을 찾거나 해상도 증가가 꼭 필요한 모델만 608 같은 고해상도를 사용해보기

실험 계획
모델 선택 및 하이퍼파라미터 설정:

ViT 기반 모델 (예: deit_base_patch16_224, vit_large_patch16_224)을 앙상블 후보에 추가

Early Stopping patience를 5로 되돌리고, lr은 1e-4부터 시작하는 실험을 진행

데이터 증강 전략:

train.py에서 ImgDataset을 만들 때, valid_ds에 tf_heavy 옵션을 비활성화해서 Test 데이터와 동일한 조건으로 평가

transform.py에서 build_valid_tf는 _finalize_to_square(size)와 A.Normalize만 남기고 모든 증강 기법을 제거build_train_tf_base와 build_train_tf_heavy의 증강 확률을 미세하게 조정해서 과도한 훼손을 방지

앙상블 개선:

ensemble.py를 수정해서 OOF 예측 파일을 기반으로 최적의 가중치를 찾는 로직을 추가하거나,
단순 합산 대신 평균 확률을 사용하는 방식으로 바꿔보기
